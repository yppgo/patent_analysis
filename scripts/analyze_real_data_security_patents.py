"""
ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒæŠ€æœ¯ç©ºç™½è¯†åˆ«åˆ†æ
æ•°æ®æ¥æº: data/clean_patents1_with_topics_filled.xlsx (clear sheet)
æ–¹æ³•: Angle-Based Outlier Detection (ABOD)
"""

import pandas as pd
import numpy as np
from pyod.models.abod import ABOD
from sentence_transformers import SentenceTransformer
from typing import Dict
import warnings
warnings.filterwarnings('ignore')

def load_real_patent_data(file_path: str = 'data/clean_patents1_with_topics_filled.xlsx', 
                          sheet_name: str = 'clear',
                          sample_size: int = 500) -> pd.DataFrame:
    """
    åŠ è½½çœŸå®çš„ä¸“åˆ©æ•°æ®
    
    å‚æ•°:
        file_path: Excel æ–‡ä»¶è·¯å¾„
        sheet_name: Sheet åç§°
        sample_size: é‡‡æ ·æ•°é‡ï¼ˆä¸ºäº†åŠ å¿«å¤„ç†é€Ÿåº¦ï¼‰
    """
    print(f"\nğŸ“¥ åŠ è½½çœŸå®ä¸“åˆ©æ•°æ®...")
    print(f"  æ–‡ä»¶: {file_path}")
    print(f"  Sheet: {sheet_name}")
    
    # è¯»å–æ•°æ®
    df = pd.read_excel(file_path, sheet_name=sheet_name)
    print(f"  âœ“ åŸå§‹æ•°æ®: {len(df)} æ¡ä¸“åˆ©")
    
    # é€‰æ‹©éœ€è¦çš„åˆ—
    columns_needed = ['æ ‡é¢˜(è¯‘)(ç®€ä½“ä¸­æ–‡)', 'æ‘˜è¦(è¯‘)(ç®€ä½“ä¸­æ–‡)', 'IPCä¸»åˆ†ç±»å·', 'Topic_Label']
    df = df[columns_needed].copy()
    
    # é‡å‘½ååˆ—ä»¥ä¾¿å¤„ç†
    df.columns = ['æ ‡é¢˜', 'æ‘˜è¦', 'IPC', 'ä¸»é¢˜æ ‡ç­¾']
    
    # åˆ é™¤ç¼ºå¤±å€¼
    df = df.dropna(subset=['æ ‡é¢˜', 'æ‘˜è¦'])
    print(f"  âœ“ æ¸…æ´—å: {len(df)} æ¡ä¸“åˆ©")
    
    # å¦‚æœæ•°æ®å¤ªå¤šï¼Œéšæœºé‡‡æ ·
    if len(df) > sample_size:
        df = df.sample(n=sample_size, random_state=42)
        print(f"  âœ“ éšæœºé‡‡æ ·: {sample_size} æ¡ä¸“åˆ©")
    
    return df


def detect_technology_gaps_real(patents_df: pd.DataFrame, 
                                 contamination: float = 0.1) -> Dict:
    """
    ä½¿ç”¨ ABOD æ£€æµ‹æŠ€æœ¯ç©ºç™½
    
    å‚æ•°:
        patents_df: ä¸“åˆ©æ•°æ®
        contamination: ç¦»ç¾¤å€¼æ¯”ä¾‹
    """
    print("\n" + "="*70)
    print("ğŸ” å¼€å§‹æŠ€æœ¯ç©ºç™½è¯†åˆ«åˆ†æ")
    print("="*70)
    
    try:
        # æ­¥éª¤ 1: åŠ è½½æ¨¡å‹
        print("\nğŸ“¥ æ­¥éª¤ 1/4: åŠ è½½ Sentence Transformer æ¨¡å‹...")
        model = SentenceTransformer('all-MiniLM-L6-v2')
        print("  âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ: all-MiniLM-L6-v2")
        
        # æ­¥éª¤ 2: æ–‡æœ¬ç¼–ç 
        print("\nğŸ”¤ æ­¥éª¤ 2/4: å°†ä¸“åˆ©æ–‡æœ¬ç¼–ç ä¸ºå‘é‡...")
        # åˆå¹¶æ ‡é¢˜å’Œæ‘˜è¦
        patents_df['combined_text'] = patents_df['æ ‡é¢˜'] + ' ' + patents_df['æ‘˜è¦']
        
        # ç¼–ç 
        embeddings = model.encode(
            list(patents_df['combined_text']), 
            show_progress_bar=True,
            batch_size=32
        )
        print(f"  âœ“ ç¼–ç å®Œæˆ: {embeddings.shape[0]} ä¸ªä¸“åˆ© -> {embeddings.shape[1]} ç»´å‘é‡")
        
        # æ­¥éª¤ 3: ç¦»ç¾¤å€¼æ£€æµ‹
        print("\nğŸ¯ æ­¥éª¤ 3/4: æ‰§è¡Œ Angle-Based Outlier Detection...")
        print(f"  å‚æ•°: contamination={contamination}, n_neighbors=5, method='fast'")
        
        detector = ABOD(contamination=contamination, n_neighbors=5, method='fast')
        outlier_labels = detector.fit_predict(embeddings)
        outlier_scores = detector.decision_scores_
        
        n_outliers = sum(outlier_labels == 1)
        print(f"  âœ“ æ£€æµ‹å®Œæˆ: å‘ç° {n_outliers} ä¸ªæ½œåœ¨æŠ€æœ¯ç©ºç™½ (å æ¯” {n_outliers/len(patents_df)*100:.1f}%)")
        
        # æ­¥éª¤ 4: æ•´ç†ç»“æœ
        print("\nğŸ“Š æ­¥éª¤ 4/4: æ•´ç†åˆ†æç»“æœ...")
        patents_df['is_outlier'] = outlier_labels
        patents_df['outlier_score'] = outlier_scores
        
        # æå–ç¦»ç¾¤ä¸“åˆ©
        gap_patents = patents_df[patents_df['is_outlier'] == 1].copy()
        gap_patents = gap_patents.sort_values('outlier_score', ascending=False)
        
        # æå–ä¸»æµä¸“åˆ©
        mainstream_patents = patents_df[patents_df['is_outlier'] == 0].copy()
        
        print(f"  âœ“ è¯†åˆ«å‡º {len(gap_patents)} ä¸ªæ½œåœ¨æŠ€æœ¯ç©ºç™½")
        print(f"  âœ“ è¯†åˆ«å‡º {len(mainstream_patents)} ä¸ªä¸»æµæŠ€æœ¯")
        
        return {
            'gap_patents': gap_patents,
            'mainstream_patents': mainstream_patents,
            'statistics': {
                'total_patents': len(patents_df),
                'gap_count': len(gap_patents),
                'mainstream_count': len(mainstream_patents),
                'gap_ratio': len(gap_patents) / len(patents_df)
            }
        }
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return {'error': str(e)}


def display_results(results: Dict):
    """å±•ç¤ºåˆ†æç»“æœ"""
    if 'error' in results:
        print(f"\nâŒ åˆ†æå¤±è´¥: {results['error']}")
        return
    
    print("\n" + "="*70)
    print("ğŸ“ˆ åˆ†æç»“æœæ±‡æ€»")
    print("="*70)
    
    stats = results['statistics']
    print(f"\næ€»ä¸“åˆ©æ•°: {stats['total_patents']}")
    print(f"ä¸»æµæŠ€æœ¯: {stats['mainstream_count']} ({stats['mainstream_count']/stats['total_patents']*100:.1f}%)")
    print(f"æŠ€æœ¯ç©ºç™½: {stats['gap_count']} ({stats['gap_ratio']*100:.1f}%)")
    
    # æ˜¾ç¤ºæŠ€æœ¯ç©ºç™½
    print("\n" + "="*70)
    print("ğŸŒŸ æ½œåœ¨æŠ€æœ¯ç©ºç™½ï¼ˆåˆ›æ–°æœºä¼šï¼‰- Top 10")
    print("="*70)
    
    gap_patents = results['gap_patents']
    for i, (idx, patent) in enumerate(gap_patents.head(10).iterrows(), 1):
        print(f"\nã€ç©ºç™½ {i}ã€‘ç¦»ç¾¤åˆ†æ•°: {patent['outlier_score']:.4f}")
        print(f"  æ ‡é¢˜: {patent['æ ‡é¢˜']}")
        print(f"  IPC: {patent['IPC']}")
        if pd.notna(patent.get('ä¸»é¢˜æ ‡ç­¾')):
            print(f"  ä¸»é¢˜: {patent['ä¸»é¢˜æ ‡ç­¾']}")
        print(f"  æ‘˜è¦: {patent['æ‘˜è¦'][:100]}...")
    
    # æ˜¾ç¤ºä¸»æµæŠ€æœ¯
    print("\n" + "="*70)
    print("ğŸ“š ä¸»æµæŠ€æœ¯ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰")
    print("="*70)
    
    mainstream_patents = results['mainstream_patents']
    for i, (idx, patent) in enumerate(mainstream_patents.head(5).iterrows(), 1):
        print(f"\nã€ä¸»æµ {i}ã€‘")
        print(f"  æ ‡é¢˜: {patent['æ ‡é¢˜']}")
        print(f"  IPC: {patent['IPC']}")
        if pd.notna(patent.get('ä¸»é¢˜æ ‡ç­¾')):
            print(f"  ä¸»é¢˜: {patent['ä¸»é¢˜æ ‡ç­¾']}")
    
    # æŒ‰ä¸»é¢˜ç»Ÿè®¡
    if 'ä¸»é¢˜æ ‡ç­¾' in gap_patents.columns:
        print("\n" + "="*70)
        print("ğŸ“Š æŠ€æœ¯ç©ºç™½çš„ä¸»é¢˜åˆ†å¸ƒ")
        print("="*70)
        topic_dist = gap_patents['ä¸»é¢˜æ ‡ç­¾'].value_counts()
        for topic, count in topic_dist.head(10).items():
            if pd.notna(topic):
                print(f"  {topic}: {count} ä¸ª")
    
    # ä¿å­˜ç»“æœ
    print("\n" + "="*70)
    print("ğŸ’¾ ä¿å­˜ç»“æœ...")
    print("="*70)
    
    # ä¿å­˜æŠ€æœ¯ç©ºç™½åˆ° Excel
    output_file = 'data/technology_gaps_analysis_result.xlsx'
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        gap_patents[['æ ‡é¢˜', 'æ‘˜è¦', 'IPC', 'ä¸»é¢˜æ ‡ç­¾', 'outlier_score']].to_excel(
            writer, sheet_name='æŠ€æœ¯ç©ºç™½', index=False
        )
        mainstream_patents[['æ ‡é¢˜', 'æ‘˜è¦', 'IPC', 'ä¸»é¢˜æ ‡ç­¾']].head(100).to_excel(
            writer, sheet_name='ä¸»æµæŠ€æœ¯ç¤ºä¾‹', index=False
        )
    
    print(f"  âœ“ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸš€ Patent-DeepScientist - çœŸå®æ•°æ®æŠ€æœ¯ç©ºç™½è¯†åˆ«")
    print("   æ–¹æ³•: Angle-Based Outlier Detection (ABOD)")
    print("   æ•°æ®: æ•°æ®å®‰å…¨é¢†åŸŸä¸“åˆ© (clear sheet)")
    print("="*70)
    
    # åŠ è½½çœŸå®æ•°æ®
    data = load_real_patent_data(sample_size=500)
    
    print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(f"  ä¸“åˆ©æ•°é‡: {len(data)}")
    print(f"  IPC åˆ†ç±»æ•°: {data['IPC'].nunique()}")
    if 'ä¸»é¢˜æ ‡ç­¾' in data.columns:
        print(f"  ä¸»é¢˜æ•°é‡: {data['ä¸»é¢˜æ ‡ç­¾'].nunique()}")
    
    # æ‰§è¡Œåˆ†æ
    results = detect_technology_gaps_real(data, contamination=0.1)
    
    # å±•ç¤ºç»“æœ
    display_results(results)
    
    print("\n" + "="*70)
    print("âœ… åˆ†æå®Œæˆ")
    print("="*70)
    print("\nğŸ’¡ è§£è¯»:")
    print("  - ç¦»ç¾¤åˆ†æ•°è¶Šé«˜ï¼Œè¡¨ç¤ºè¯¥ä¸“åˆ©åœ¨è¯­ä¹‰ç©ºé—´ä¸­è¶Šåç¦»ä¸»æµ")
    print("  - è¿™äº›ç¦»ç¾¤ä¸“åˆ©å¯èƒ½ä»£è¡¨æ–°å…´çš„æŠ€æœ¯æ–¹å‘æˆ–æœªè¢«å……åˆ†æ¢ç´¢çš„é¢†åŸŸ")
    print("  - å»ºè®®è¿›ä¸€æ­¥è°ƒç ”è¿™äº›æŠ€æœ¯ç©ºç™½ï¼Œè¯„ä¼°å…¶å•†ä¸šä»·å€¼å’Œå¯è¡Œæ€§")
    print()
