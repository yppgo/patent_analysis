"""
æ•°æ®é¢„è§ˆå·¥å…·
ä¸º Strategist å’Œ Methodologist æä¾›æ•°æ®ç»“æ„å’Œç»Ÿè®¡ä¿¡æ¯
"""

import json
import pandas as pd
import numpy as np
from typing import Dict, Any, Optional, List
from pathlib import Path


class DataPreview:
    """
    æ•°æ®é¢„è§ˆç”Ÿæˆå™¨
    åœ¨è“å›¾è®¾è®¡å‰ä¸ºæ™ºèƒ½ä½“æä¾›æ•°æ®æ´å¯Ÿ
    """
    
    # é«˜åŸºæ•°é˜ˆå€¼
    HIGH_CARDINALITY_THRESHOLD = 50
    
    # é€‚åˆä½œä¸ºç±»åˆ«å˜é‡çš„æœ€å¤§å”¯ä¸€å€¼æ•°
    CATEGORY_VAR_MAX_UNIQUE = 20

    # åˆ†éš”ç¬¦åˆ—æ£€æµ‹ï¼šä»…å¯¹è¿™äº›å…³é”®è¯åˆ—æ›´å¯ä¿¡
    DELIMITER_COLNAME_KEYWORDS = [
        "å‘æ˜äºº",
        "ç”³è¯·",
        "ä¸“åˆ©",
        "åœ°å€",
        "å›½å®¶",
        "åœ°åŒº",
        "IPC",
    ]

    # å‰ç¼€æå–å»ºè®®ä»…å¯¹è¿™äº›å­—æ®µæ›´å¯ä¿¡ï¼ˆé¿å…æ ‡é¢˜/æ‘˜è¦ç±»é•¿æ–‡æœ¬è¯¯å¯¼ï¼‰
    PREFIX_COLNAME_KEYWORDS = [
        "IPC",
        "åˆ†ç±»",
        "åœ°åŒº",
        "å›½å®¶",
    ]

    # å…³é”®åˆ—æ ·ä¾‹è¡Œï¼ˆä»…æ³¨å…¥è¿™äº›åˆ—ï¼Œé¿å… Prompt è¿‡é•¿ï¼‰
    KEY_SAMPLE_COLUMNS = [
        "åºå·",
        "å…¬å¼€(å…¬å‘Š)å·",
        "æˆæƒæ—¥",
        "IPCä¸»åˆ†ç±»å·",
        "è¢«å¼•ç”¨ä¸“åˆ©æ•°é‡",
        "å¼•ç”¨ä¸“åˆ©æ•°é‡",
        "å‘æ˜äºº",
        "Topic_Label",
    ]
    
    @classmethod
    def from_file(cls, file_path: str, sheet_name: str = None) -> 'DataPreview':
        """ä»æ–‡ä»¶åŠ è½½æ•°æ®å¹¶ç”Ÿæˆé¢„è§ˆ"""
        path = Path(file_path)
        
        # è½¬æ¢ä¸ºå°å†™è¿›è¡Œæ¯”è¾ƒï¼Œæ”¯æŒå¤§å°å†™ä¸æ•æ„Ÿ
        suffix_lower = path.suffix.lower()
        
        if suffix_lower in ['.xlsx', '.xls']:
            df = pd.read_excel(file_path, sheet_name=sheet_name or 0)
        elif suffix_lower == '.csv':
            df = pd.read_csv(file_path)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {path.suffix}")
        
        return cls(df)
    
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self._preview = None
    
    def generate(self) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„æ•°æ®é¢„è§ˆ"""
        if self._preview is not None:
            return self._preview
        
        self._preview = {
            "basic": self._generate_basic_info(),
            "columns": self._generate_column_info(),
            "recommendations": self._generate_recommendations(),
            "sample_rows": self._generate_sample_rows()
        }
        
        return self._preview
    
    def _generate_basic_info(self) -> Dict[str, Any]:
        """ç”ŸæˆåŸºç¡€ä¿¡æ¯"""
        return {
            "shape": {
                "rows": int(self.df.shape[0]),
                "columns": int(self.df.shape[1])
            },
            "column_names": self.df.columns.tolist(),
            "memory_usage_mb": round(self.df.memory_usage(deep=True).sum() / 1024 / 1024, 2)
        }
    
    def _generate_column_info(self) -> Dict[str, Dict]:
        """ç”Ÿæˆæ¯åˆ—çš„è¯¦ç»†ä¿¡æ¯"""
        columns_info = {}
        
        for col in self.df.columns:
            col_data = self.df[col]
            dtype = str(col_data.dtype)
            nunique = col_data.nunique()
            null_count = int(col_data.isnull().sum())
            
            info = {
                "dtype": dtype,
                "unique_count": int(nunique),
                "null_count": null_count,
                "null_percent": round(null_count / len(self.df) * 100, 1)
            }
            
            # åˆ¤æ–­åˆ—è§’è‰²
            if nunique == len(self.df):
                info["role"] = "IDåˆ—ï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰"
                info["sample"] = col_data.head(2).tolist()
            
            elif dtype in ['int64', 'float64']:
                # æ•°å€¼åˆ—ï¼šç»Ÿè®¡ä¿¡æ¯
                info["role"] = "æ•°å€¼åˆ—"
                info["stats"] = {
                    "mean": round(float(col_data.mean()), 2),
                    "median": round(float(col_data.median()), 2),
                    "min": float(col_data.min()),
                    "max": float(col_data.max()),
                    "std": round(float(col_data.std()), 2)
                }
            
            elif nunique <= self.CATEGORY_VAR_MAX_UNIQUE:
                # ä½åŸºæ•°åˆ—ï¼šé€‚åˆåšç±»åˆ«å˜é‡
                info["role"] = "ç±»åˆ«åˆ—ï¼ˆé€‚åˆåšåˆ†ç±»å˜é‡ï¼‰"
                info["categories"] = col_data.value_counts().head(10).to_dict()
            
            elif nunique <= self.HIGH_CARDINALITY_THRESHOLD:
                # ä¸­ç­‰åŸºæ•°åˆ—
                info["role"] = "ä¸­ç­‰åŸºæ•°åˆ—"
                info["top_10"] = col_data.value_counts().head(10).to_dict()
                info["sample"] = col_data.dropna().head(3).tolist()
            
            else:
                # é«˜åŸºæ•°åˆ—ï¼šéœ€è¦è­¦å‘Š
                info["role"] = "é«˜åŸºæ•°åˆ—"
                info["warning"] = f"å”¯ä¸€å€¼è¿‡å¤š({nunique})ï¼Œä¸é€‚åˆç›´æ¥ä½œä¸ºç±»åˆ«å˜é‡"
                info["suggestion"] = "è€ƒè™‘ï¼š1)æå–å‰ç¼€åˆ†ç»„ 2)èšåˆä¸ºTop-N+å…¶ä»– 3)è½¬æ¢ä¸ºæ•°å€¼ç‰¹å¾"
                info["sample"] = col_data.dropna().head(3).tolist()
                
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥æå–å‰ç¼€
                if dtype == 'object' and any(k in col for k in self.PREFIX_COLNAME_KEYWORDS):
                    sample_series = col_data.dropna().astype(str)
                    if len(sample_series) > 0:
                        avg_len = sample_series.head(50).str.len().mean()
                        # é•¿æ–‡æœ¬åˆ—å‰ç¼€æ— æ„ä¹‰ï¼Œè·³è¿‡
                        if avg_len <= 40:
                            sample_val = str(sample_series.iloc[0])
                            if len(sample_val) >= 4:
                                prefix_nunique = sample_series.str[:4].nunique()
                                if prefix_nunique < nunique:
                                    info["prefix_suggestion"] = f"æå–å‰4ä½å¯å‡å°‘åˆ°{prefix_nunique}ä¸ªç±»åˆ«"
            
            # å¢å¼ºæ£€æµ‹ï¼šæ—¥æœŸåˆ—
            if dtype == 'object' and not info.get("role", "").startswith("ID"):
                date_info = self._detect_date_column(col_data, col)
                if date_info:
                    info.update(date_info)
            
            # å¢å¼ºæ£€æµ‹ï¼šåˆ†éš”ç¬¦åˆ—ï¼ˆå¦‚ "å¼ ä¸‰;æå››;ç‹äº”"ï¼‰
            if dtype == 'object' and not info.get("role", "").startswith("ID"):
                delimiter_info = self._detect_delimiter_column(col_data, col)
                if delimiter_info:
                    info.update(delimiter_info)
            
            columns_info[col] = info
        
        return columns_info
    
    def _detect_date_column(self, col_data: pd.Series, col_name: str) -> Optional[Dict]:
        """æ£€æµ‹æ—¥æœŸåˆ—"""
        # æ ¹æ®åˆ—ååˆ¤æ–­
        date_keywords = ['æ—¥', 'date', 'time', 'æ—¶é—´', 'å¹´', 'æœˆ']
        if any(kw in col_name.lower() for kw in date_keywords):
            sample = col_data.dropna().head(3).tolist()
            try:
                # å°è¯•è§£ææ—¥æœŸ
                parsed = pd.to_datetime(col_data.dropna().head(100), errors='coerce')
                valid_ratio = parsed.notna().sum() / min(100, len(col_data.dropna()))
                if valid_ratio > 0.8:
                    min_year = parsed.dropna().dt.year.min()
                    max_year = parsed.dropna().dt.year.max()
                    return {
                        "role": "æ—¥æœŸåˆ—",
                        "date_range": f"{min_year}~{max_year}",
                        "derived_suggestion": f"å¯è®¡ç®—æ—¶é—´å·®ï¼ˆå¦‚ï¼š2026 - å¹´ä»½ = ä¸“åˆ©å¹´é¾„ï¼‰",
                        "sample": sample
                    }
            except:
                pass
        return None
    
    def _detect_delimiter_column(self, col_data: pd.Series, col_name: str) -> Optional[Dict]:
        """æ£€æµ‹åˆ†éš”ç¬¦åˆ—ï¼ˆå¦‚å¤šä¸ªå‘æ˜äººç”¨åˆ†å·åˆ†éš”ï¼‰"""
        # ä»…å¯¹â€œçœ‹èµ·æ¥åƒåˆ—è¡¨å­—æ®µâ€çš„åˆ—å¯ç”¨ï¼Œé¿å…å¯¹æ‘˜è¦/æ ‡é¢˜ç­‰é•¿æ–‡æœ¬è¯¯æŠ¥
        if not any(k in col_name for k in self.DELIMITER_COLNAME_KEYWORDS):
            return None

        # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†éš”ç¬¦ï¼ˆé»˜è®¤ä¸æ£€æµ‹è‹±æ–‡é€—å·ï¼Œä¸­æ–‡æ–‡æœ¬å¤ªå®¹æ˜“è¯¯æŠ¥ï¼‰
        delimiters = [';', '|', 'ï¼›']
        sample_values = col_data.dropna().astype(str).head(50)

        # è¿›ä¸€æ­¥é™å™ªï¼šå¦‚æœæ–‡æœ¬å¾ˆé•¿ï¼Œå¾€å¾€æ˜¯è‡ªç„¶è¯­è¨€è€Œä¸æ˜¯åˆ—è¡¨
        if len(sample_values) > 0:
            avg_len = sample_values.str.len().mean()
            if avg_len > 80:
                return None
        
        for delim in delimiters:
            # è®¡ç®—åŒ…å«åˆ†éš”ç¬¦çš„æ¯”ä¾‹
            contains_delim = sample_values.str.contains(delim, regex=False, na=False)
            if contains_delim.sum() / len(sample_values) > 0.3:
                # è®¡ç®—å¹³å‡å…ƒç´ æ•°
                avg_count = sample_values.str.split(delim).apply(len).mean()
                if avg_count > 1.5:
                    suggestion = self._make_delimiter_suggestion(col_name, delim)
                    return {
                        "has_delimiter": True,
                        "delimiter": delim,
                        "avg_items": round(avg_count, 1),
                        "derived_suggestion": suggestion
                    }
        return None

    def _make_delimiter_suggestion(self, col_name: str, delim: str) -> str:
        """æ ¹æ®åˆ—åç”Ÿæˆæ›´è´´åˆè¯­ä¹‰çš„æ´¾ç”Ÿå»ºè®®"""
        if "å‘æ˜äºº" in col_name:
            return f"å¯æŒ‰'{delim}'åˆ†å‰²åè®¡æ•°ï¼ˆå‘æ˜äººæ•°é‡ï¼‰"
        if "è¢«å¼•ç”¨" in col_name and "ä¸“åˆ©" in col_name:
            return f"å¯æŒ‰'{delim}'åˆ†å‰²åè®¡æ•°ï¼ˆè¢«å¼•ç”¨ä¸“åˆ©æ¡ç›®æ•°/å‰å‘å¼•æ–‡æ•°é‡æ ¸éªŒï¼‰"
        if "å¼•ç”¨" in col_name and "ä¸“åˆ©" in col_name:
            return f"å¯æŒ‰'{delim}'åˆ†å‰²åè®¡æ•°ï¼ˆå¼•ç”¨ä¸“åˆ©æ¡ç›®æ•°/åå‘å¼•æ–‡æ•°é‡æ ¸éªŒï¼‰"
        return f"å¯æŒ‰'{delim}'åˆ†å‰²åè®¡æ•°ï¼ˆåˆ—è¡¨é•¿åº¦ç‰¹å¾ï¼‰"
    
    def _generate_recommendations(self) -> List[Dict]:
        """ç”Ÿæˆæ•°æ®ä½¿ç”¨å»ºè®®"""
        recommendations = []
        
        # è¯†åˆ«æ½œåœ¨çš„IDåˆ—
        id_cols = [col for col in self.df.columns 
                   if self.df[col].nunique() == len(self.df)]
        if id_cols:
            recommendations.append({
                "type": "info",
                "message": f"è¯†åˆ«åˆ°IDåˆ—: {id_cols}ï¼Œè¿™äº›åˆ—å¯ç”¨äºæ•°æ®å…³è”"
            })

        # è¯†åˆ«æ—¥æœŸåˆ—ï¼ˆç”¨äºæ´¾ç”Ÿç‰¹å¾æç¤ºï¼ŒåŒæ—¶é¿å…è¢«è¯¯åˆ¤ä¸ºâ€œé«˜åŸºæ•°åˆ†ç±»åˆ—é£é™©â€ï¼‰
        date_cols = []
        for col in self.df.columns:
            if self.df[col].dtype == object:
                date_info = self._detect_date_column(self.df[col], col)
                if date_info:
                    date_cols.append(col)
        if date_cols:
            recommendations.append({
                "type": "info",
                "message": f"æ—¥æœŸåˆ—: {date_cols}ï¼Œå¯æ´¾ç”Ÿä¸“åˆ©å¹´é¾„/æ—¶é—´å·®ç­‰è¿ç»­å˜é‡"
            })
        
        # è¯†åˆ«é«˜åŸºæ•°åˆ—ï¼ˆä»…é’ˆå¯¹éæ•°å€¼åˆ—ï¼›æ•°å€¼åˆ—é«˜å”¯ä¸€å€¼æ˜¯æ­£å¸¸çš„ï¼Œä¸åº”æç¤ºâ€œåˆ†ç±»å˜é‡â€é£é™©ï¼‰
        high_card_cols = [
            col
            for col in self.df.columns
            if (self.df[col].dtype == object)
            and (col not in date_cols)
            and (self.df[col].nunique() > self.HIGH_CARDINALITY_THRESHOLD)
            and (self.df[col].nunique() < len(self.df))
        ]
        if high_card_cols:
            recommendations.append({
                "type": "warning",
                "message": f"é«˜åŸºæ•°åˆ—: {high_card_cols}ï¼Œä¸é€‚åˆç›´æ¥ä½œä¸ºåˆ†ç±»å˜é‡ï¼Œéœ€è¦é¢„å¤„ç†"
            })
        
        # è¯†åˆ«é€‚åˆåšç±»åˆ«å˜é‡çš„åˆ—ï¼ˆä»…é’ˆå¯¹éæ•°å€¼åˆ—ï¼‰
        category_cols = [
            col
            for col in self.df.columns
            if (self.df[col].dtype == object)
            and (2 <= self.df[col].nunique() <= self.CATEGORY_VAR_MAX_UNIQUE)
        ]
        if category_cols:
            recommendations.append({
                "type": "info",
                "message": f"é€‚åˆåšç±»åˆ«å˜é‡çš„åˆ—: {category_cols}"
            })
        
        # è¯†åˆ«æ•°å€¼åˆ—
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        numeric_cols = [col for col in numeric_cols if self.df[col].nunique() < len(self.df)]
        if numeric_cols:
            recommendations.append({
                "type": "info",
                "message": f"æ•°å€¼åˆ—ï¼ˆå¯åšè¿ç»­å˜é‡ï¼‰: {numeric_cols}"
            })
        
        return recommendations
    
    def _generate_sample_rows(self, n: int = 5) -> List[Dict]:
        """ç”Ÿæˆæ ·ä¾‹è¡Œï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…å¤ªé•¿ï¼‰"""
        sample_df = self.df.head(n)

        # ä¼˜å…ˆä½¿ç”¨â€œå…³é”®åˆ—å­é›†â€
        key_cols = [c for c in self.KEY_SAMPLE_COLUMNS if c in sample_df.columns]
        if not key_cols:
            key_cols = sample_df.columns[:5].tolist()

        records = sample_df[key_cols].to_dict(orient='records')

        # æˆªæ–­é•¿æ–‡æœ¬ï¼Œé¿å… Prompt è¿‡é•¿
        truncated = []
        for row in records:
            new_row = {}
            for k, v in row.items():
                if isinstance(v, str):
                    s = v.replace("\n", " ").replace("\r", " ")
                    if len(s) > 80:
                        s = s[:80] + "..."
                    new_row[k] = s
                else:
                    new_row[k] = v
            truncated.append(new_row)

        return truncated
    
    def to_prompt_string(self) -> str:
        """ç”Ÿæˆå¯ç›´æ¥åµŒå…¥Promptçš„å­—ç¬¦ä¸²"""
        preview = self.generate()
        
        lines = []
        lines.append("ğŸ“Š **æ•°æ®é¢„è§ˆ**")
        lines.append(f"- æ•°æ®å½¢çŠ¶: {preview['basic']['shape']['rows']} è¡Œ Ã— {preview['basic']['shape']['columns']} åˆ—")
        lines.append("")
        
        lines.append("**åˆ—ä¿¡æ¯ï¼š**")
        for col, info in preview['columns'].items():
            role = info.get('role', 'æœªçŸ¥')
            line = f"- `{col}` ({info['dtype']}): {role}"
            
            # æ—¥æœŸåˆ—
            if info.get('role') == 'æ—¥æœŸåˆ—':
                line += f" ğŸ“… èŒƒå›´:{info.get('date_range', 'N/A')}"
                if 'derived_suggestion' in info:
                    line += f" â†’ {info['derived_suggestion']}"
            # åˆ†éš”ç¬¦åˆ—
            elif info.get('has_delimiter'):
                line += f" ğŸ“‹ å«åˆ†éš”ç¬¦'{info['delimiter']}', å¹³å‡{info['avg_items']}é¡¹"
                if 'derived_suggestion' in info:
                    line += f" â†’ {info['derived_suggestion']}"
            # è­¦å‘Š
            elif 'warning' in info:
                line += f" âš ï¸ {info['warning']}"
                if 'prefix_suggestion' in info:
                    line += f" ğŸ’¡ {info['prefix_suggestion']}"
            # æ•°å€¼åˆ—
            elif 'stats' in info:
                stats = info['stats']
                line += f" [å‡å€¼:{stats['mean']}, èŒƒå›´:{stats['min']}~{stats['max']}]"
            # ç±»åˆ«åˆ—
            elif 'categories' in info:
                cats = list(info['categories'].keys())[:5]
                line += f" ç±»åˆ«: {cats}"
            
            lines.append(line)
        
        lines.append("")
        lines.append("**å»ºè®®ï¼š**")
        for rec in preview['recommendations']:
            icon = "â„¹ï¸" if rec['type'] == 'info' else "âš ï¸"
            lines.append(f"{icon} {rec['message']}")
        
        # æ·»åŠ æ´¾ç”Ÿå˜é‡å»ºè®®
        lines.append("")
        lines.append("**å¯æ´¾ç”Ÿçš„å˜é‡ï¼š**")
        for col, info in preview['columns'].items():
            if info.get('derived_suggestion'):
                lines.append(f"- `{col}`: {info['derived_suggestion']}")

        # å…³é”®åˆ—æ ·ä¾‹è¡Œï¼ˆå‰5è¡Œï¼‰
        lines.append("")
        lines.append("**å…³é”®åˆ—æ ·ä¾‹ï¼ˆå‰5è¡Œï¼‰ï¼š**")
        lines.append(json.dumps(preview.get('sample_rows', []), ensure_ascii=False, indent=2))
        
        return "\n".join(lines)


def generate_data_preview(file_path: str, sheet_name: str = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆæ•°æ®é¢„è§ˆ"""
    preview = DataPreview.from_file(file_path, sheet_name)
    return preview.generate()


def generate_preview_prompt(file_path: str, sheet_name: str = None) -> str:
    """ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆå¯åµŒå…¥Promptçš„é¢„è§ˆå­—ç¬¦ä¸²"""
    preview = DataPreview.from_file(file_path, sheet_name)
    return preview.to_prompt_string()
