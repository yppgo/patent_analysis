"""
Coding Agent V4.2 - èåˆç»ˆç«¯å’Œæ–‡ä»¶æ“ä½œèƒ½åŠ›

æ–°å¢ç‰¹æ€§ï¼š
1. [Python REPL] - æœ‰çŠ¶æ€çš„ä»£ç æ‰§è¡Œç¯å¢ƒ
2. [Shellå‘½ä»¤] - ç»ˆç«¯æ“ä½œèƒ½åŠ›ï¼ˆls, mkdir, pip install ç­‰ï¼‰
3. [æ–‡ä»¶æ“ä½œ] - è¯»å†™æ–‡ä»¶ã€æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
4. [V4.1åŠŸèƒ½] - ä¿ç•™ V4.1 çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼ˆé”™è¯¯æ£€æµ‹ã€æ–‡ä»¶è·¯å¾„æ³¨å…¥ç­‰ï¼‰
"""

import json
import re
import pandas as pd
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from src.agents.base_agent import BaseAgent
from src.tools.repl import PythonREPL
from src.tools.os_tools import OSTools


# é”™è¯¯ç±»å‹æ˜ å°„ä¸ä¿®å¤æç¤º
ERROR_FIX_PROMPTS = {
    "SyntaxError": "æ£€æµ‹åˆ°è¯­æ³•é”™è¯¯ï¼Œè¯·ä¿®æ­£ä»£ç è¯­æ³•ï¼Œç¡®ä¿æ‰€æœ‰æ‹¬å·/å¼•å·é—­åˆï¼Œç¼©è¿›æ­£ç¡®",
    "KeyError": "æ£€æµ‹åˆ°é”®ä¸å­˜åœ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥DataFrameåˆ—åæ˜¯å¦æ­£ç¡®æ˜ å°„ï¼Œå®é™…åˆ—åï¼š{actual_columns}",
    "TypeError": "æ£€æµ‹åˆ°ç±»å‹é”™è¯¯ï¼Œè¯·æ£€æŸ¥å‡½æ•°å‚æ•°ç±»å‹å’Œè¿”å›å€¼ç±»å‹",
    "AttributeError": "æ£€æµ‹åˆ°å±æ€§é”™è¯¯ï¼Œè¯·æ£€æŸ¥å¯¹è±¡æ˜¯å¦æœ‰è¯¥å±æ€§/æ–¹æ³•",
    "ValueError": "æ£€æµ‹åˆ°å€¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ•°æ®çš„å€¼æ˜¯å¦åˆæ³•",
    "ImportError": "æ£€æµ‹åˆ°å¯¼å…¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥åº“æ˜¯å¦å·²å®‰è£…æˆ–å¯¼å…¥è¯­å¥æ˜¯å¦æ­£ç¡®",
    "ModuleNotFoundError": "æ£€æµ‹åˆ°æ¨¡å—æœªæ‰¾åˆ°ï¼Œè¯·ä½¿ç”¨ execute_shell å·¥å…·å®‰è£…ï¼špip install <package>",
    "FileNotFoundError": "æ£€æµ‹åˆ°æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·ä½¿ç”¨ execute_shell æ£€æŸ¥æ–‡ä»¶è·¯å¾„",
}


class CodingAgentV4_2(BaseAgent):
    """
    Coding Agent V4.2 - ç»ˆç«¯å¢å¼ºç‰ˆ
    
    æ ¸å¿ƒèƒ½åŠ›ï¼š
    1. Python REPLï¼ˆæœ‰çŠ¶æ€æ‰§è¡Œï¼‰
    2. Shell å‘½ä»¤ï¼ˆæ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼‰
    3. æ™ºèƒ½é”™è¯¯æ¢å¤ï¼ˆV4.1 ç»§æ‰¿ï¼‰
    4. æ–‡ä»¶è·¯å¾„æ³¨å…¥ï¼ˆV4.1 ç»§æ‰¿ï¼‰
    """
    
    def __init__(self, llm_client, test_data=None, max_iterations=15, logger=None):
        super().__init__("CodingAgentV4.2", llm_client, logger)
        self.test_data = test_data
        self.max_iterations = max_iterations
        
        # æ ¸å¿ƒç»„ä»¶
        self.repl = PythonREPL()  # æœ‰çŠ¶æ€çš„ Python ç¯å¢ƒ
        self.raw_llm = llm_client.get_llm() if hasattr(llm_client, 'get_llm') else llm_client
        
        # é”™è¯¯å†å²ï¼ˆç”¨äºæ£€æµ‹é‡å¤é”™è¯¯ï¼‰
        self.error_history = []
        
        # åˆ›å»ºå·¥å…·å’Œ agent
        self.tools = self._create_tools()
        self.agent = self._build_agent()
    
    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ‰§è¡Œè§„æ ¼ï¼Œç”Ÿæˆå¹¶æ‰§è¡Œä»£ç """
        execution_spec = input_data.get('execution_spec', {})
        test_data = input_data.get('test_data', self.test_data)
        previous_result = input_data.get('previous_result')
        previous_error = input_data.get('previous_error')
        current_step = input_data.get('current_step', {})
        
        # æ›´æ–° test_data
        if test_data is not None:
            self.test_data = test_data
        
        func_name = execution_spec.get('function_name', 'N/A')
        self.log(f"ğŸš€ [å¼€å§‹] ç”Ÿæˆä»£ç : {func_name}")
        
        # é‡ç½®é”™è¯¯å†å²å’Œ REPL ç¯å¢ƒ
        self.error_history = []
        self.repl.reset()  # æ¯æ¬¡ä»»åŠ¡å¼€å§‹æ—¶é‡ç½®ç¯å¢ƒ
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = self._build_context_info(previous_result, previous_error)
        
        # è·å–å®é™…åˆ—å
        actual_columns = list(test_data.columns) if test_data is not None else []
        
        # æ„å»ºåˆå§‹æç¤º
        initial_message = self._build_initial_prompt(
            execution_spec, 
            context_info,
            test_data,
            actual_columns,
            current_step
        )
        
        # è°ƒç”¨ agent
        # è®¾ç½®æ›´é«˜çš„é€’å½’é™åˆ¶ä»¥é¿å…è¿‡æ—©ç»ˆæ­¢
        recursion_limit = max(50, self.max_iterations + 20)
        result = self.agent.invoke({
            "messages": [("user", initial_message)],
            "configurable": {
                "execution_spec": execution_spec,
                "test_data": test_data,
                "max_iterations": self.max_iterations,
                "actual_columns": actual_columns
            }
        }, config={"recursion_limit": recursion_limit})
        
        # æå–æœ€ç»ˆç»“æœ
        final_result = self._extract_final_result(result)
        
        self.log(f"âœ… [å®Œæˆ] ä»£ç ç”Ÿæˆå®Œæˆ")
        
        return final_result
    
    def _create_tools(self) -> List:
        """åˆ›å»ºå·¥å…·åˆ—è¡¨"""
        
        @tool
        def run_python(code: str) -> str:
            """
            åœ¨æœ‰çŠ¶æ€çš„ Python REPL ä¸­æ‰§è¡Œä»£ç ã€‚
            å˜é‡ä¼šåœ¨å¤šæ¬¡è°ƒç”¨é—´ä¿æŒã€‚
            
            âš ï¸ é‡è¦ï¼šå¿…é¡»ä½¿ç”¨ print() æ‰èƒ½çœ‹åˆ°è¾“å‡ºï¼
            
            Args:
                code: Python ä»£ç 
            
            Returns:
                æ‰§è¡Œç»“æœæˆ–é”™è¯¯ä¿¡æ¯
            """
            self.log("=" * 60)
            self.log("ğŸ [Python REPL] æ‰§è¡Œä»£ç ")
            self.log("=" * 60)
            
            # æ‰“å°ä»£ç å†…å®¹
            code_preview = code[:300] + "\n..." if len(code) > 300 else code
            self.log(f"ä»£ç :\n{code_preview}")
            self.log("-" * 60)
            
            try:
                output = self.repl.run(code)
                
                # æ‰“å°æ‰§è¡Œç»“æœ
                output_preview = output[:500] + "\n..." if len(output) > 500 else output
                self.log(f"è¾“å‡º:\n{output_preview}")
                self.log("=" * 60)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                if "Error" in output or "Traceback" in output:
                    # è§£æé”™è¯¯ç±»å‹
                    error_type, detail = self._parse_error(output)
                    
                    # è®°å½•é”™è¯¯å†å²
                    self.error_history.append({
                        'type': error_type,
                        'detail': detail,
                        'full_error': output
                    })
                    
                    # æ£€æµ‹é‡å¤é”™è¯¯
                    if self._is_repeated_error(error_type):
                        self.log(f"  âš ï¸ æ£€æµ‹åˆ°é‡å¤é”™è¯¯: {error_type}")
                        return f"âŒ é‡å¤é”™è¯¯ï¼ˆ{error_type}ï¼‰ï¼Œå·²å°è¯• {len(self.error_history)} æ¬¡ã€‚\n\n{output}\n\nğŸ›‘ è¯·å½»åº•é‡æ–°æ€è€ƒè§£å†³æ–¹æ¡ˆã€‚"
                    
                    # è·å–ä¿®å¤æç¤º
                    fix_prompt = ERROR_FIX_PROMPTS.get(error_type, "è¯·æ£€æŸ¥ä»£ç é€»è¾‘")
                    if error_type == "KeyError" and self.test_data is not None:
                        fix_prompt = fix_prompt.format(actual_columns=list(self.test_data.columns))
                    
                    self.log(f"  âš ï¸ æ‰§è¡Œå¤±è´¥: {error_type}")
                    return f"âŒ {error_type}:\n{output}\n\nğŸ’¡ ä¿®å¤å»ºè®®: {fix_prompt}"
                
                self.log("  âœ… æ‰§è¡ŒæˆåŠŸ")
                # è¿”å›è¾“å‡ºï¼Œå¦‚æœæ²¡æœ‰è¾“å‡ºåˆ™è¿”å›æˆåŠŸæ ‡è®°
                return output if output.strip() else "âœ… ä»£ç å·²æ‰§è¡Œ (æ— è¾“å‡ºï¼Œè¯·ä½¿ç”¨ print æŸ¥çœ‹ç»“æœ)"
            
            except Exception as e:
                self.log(f"  âš ï¸ æ‰§è¡Œå¼‚å¸¸: {e}")
                return f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}"

        
        @tool
        def execute_shell(command: str) -> str:
            """
            æ‰§è¡Œ Shell å‘½ä»¤ï¼ˆå¦‚ ls, mkdir, pip install, cat ç­‰ï¼‰ã€‚
            
            å¸¸ç”¨å‘½ä»¤ï¼š
            - ls / dir: åˆ—å‡ºæ–‡ä»¶
            - mkdir: åˆ›å»ºç›®å½•
            - pip install: å®‰è£…åŒ…
            - cat / type: æŸ¥çœ‹æ–‡ä»¶å†…å®¹
            - pwd / cd: æŸ¥çœ‹/åˆ‡æ¢ç›®å½•
            
            Args:
                command: Shell å‘½ä»¤
            
            Returns:
                å‘½ä»¤è¾“å‡º
            """
            self.log("=" * 60)
            self.log(f"ğŸ’» [Shell] æ‰§è¡Œå‘½ä»¤")
            self.log("=" * 60)
            self.log(f"å‘½ä»¤: {command}")
            self.log("-" * 60)
            
            output = OSTools.execute_bash(command)
            
            # æ‰“å°å®Œæ•´è¾“å‡ºï¼ˆé™åˆ¶é•¿åº¦ï¼‰
            output_preview = output[:500] + "\n..." if len(output) > 500 else output
            self.log(f"è¾“å‡º:\n{output_preview}")
            self.log("=" * 60)
            
            return output
        
        @tool
        def read_file(filepath: str, lines: int = None) -> str:
            """
            è¯»å–æ–‡ä»¶å†…å®¹ã€‚
            
            Args:
                filepath: æ–‡ä»¶è·¯å¾„
                lines: è¯»å–çš„è¡Œæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤å…¨éƒ¨ï¼‰
            
            Returns:
                æ–‡ä»¶å†…å®¹
            """
            self.log("=" * 60)
            self.log(f"ğŸ“– [æ–‡ä»¶è¯»å–] {filepath}")
            self.log("=" * 60)
            
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    if lines:
                        content = ''.join(f.readlines()[:lines])
                    else:
                        content = f.read()
                
                content_preview = content[:300] + "\n..." if len(content) > 300 else content
                self.log(f"å†…å®¹ (å‰300å­—ç¬¦):\n{content_preview}")
                self.log(f"âœ… [OK] è¯»å–æˆåŠŸï¼Œæ€»é•¿åº¦: {len(content)} å­—ç¬¦")
                self.log("=" * 60)
                return content
            
            except FileNotFoundError:
                self.log(f"âŒ [ERROR] æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
                self.log("=" * 60)
                return f"âŒ [ERROR] æ–‡ä»¶ä¸å­˜åœ¨: {filepath}"
            except Exception as e:
                self.log(f"âŒ [ERROR] è¯»å–å¤±è´¥: {e}")
                self.log("=" * 60)
                return f"âŒ [ERROR] è¯»å–å¤±è´¥: {e}"
        
        @tool
        def write_file(filepath: str, content: str) -> str:
            """
            å†™å…¥æ–‡ä»¶å†…å®¹ã€‚
            
            Args:
                filepath: æ–‡ä»¶è·¯å¾„
                content: è¦å†™å…¥çš„å†…å®¹
            
            Returns:
                æ“ä½œç»“æœ
            """
            self.log("=" * 60)
            self.log(f"âœï¸ [æ–‡ä»¶å†™å…¥] {filepath}")
            self.log("=" * 60)
            
            try:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                Path(filepath).parent.mkdir(parents=True, exist_ok=True)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                self.log(f"âœ… [OK] å†™å…¥æˆåŠŸï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
                self.log("=" * 60)
                return f"âœ… [OK] æ–‡ä»¶å·²ä¿å­˜: {filepath}"
            
            except Exception as e:
                self.log(f"âŒ [ERROR] å†™å…¥å¤±è´¥: {e}")
                self.log("=" * 60)
                return f"âŒ [ERROR] å†™å…¥å¤±è´¥: {e}"
        
        @tool
        def check_file_exists(filepath: str) -> str:
            """
            æ£€æŸ¥æ–‡ä»¶æˆ–ç›®å½•æ˜¯å¦å­˜åœ¨ã€‚
            
            Args:
                filepath: æ–‡ä»¶è·¯å¾„
            
            Returns:
                å­˜åœ¨æ€§æ£€æŸ¥ç»“æœ
            """
            path = Path(filepath)
            
            if path.exists():
                if path.is_file():
                    size = path.stat().st_size
                    return f"âœ… æ–‡ä»¶å­˜åœ¨: {filepath} (å¤§å°: {size} å­—èŠ‚)"
                elif path.is_dir():
                    files = list(path.iterdir())
                    return f"âœ… ç›®å½•å­˜åœ¨: {filepath} (åŒ…å« {len(files)} ä¸ªé¡¹ç›®)"
            else:
                return f"âŒ ä¸å­˜åœ¨: {filepath}"
        
        return [
            run_python,
            execute_shell,
            read_file,
            write_file,
            check_file_exists
        ]
    
    def _build_agent(self):
        """æ„å»º ReAct agent"""
        return create_react_agent(self.raw_llm, self.tools)
    
    def _build_context_info(
        self, 
        previous_result: Any, 
        previous_error: Optional[str]
    ) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_info = ""
        
        if previous_result is not None:
            context_info += f"""
ğŸ“¦ **å‰ä¸€æ­¥çš„å®é™…è¾“å‡ºï¼š**
ç±»å‹: {type(previous_result).__name__}
"""
            if isinstance(previous_result, pd.DataFrame):
                context_info += f"å½¢çŠ¶: {previous_result.shape}\n"
                context_info += f"åˆ—: {list(previous_result.columns)}\n"
        
        if previous_error:
            context_info += f"""
âš ï¸ **å‰ä¸€æ¬¡æ‰§è¡Œçš„é”™è¯¯ï¼š**
{previous_error}

è¯·ç‰¹åˆ«æ³¨æ„ä¿®å¤è¿™ä¸ªé”™è¯¯ï¼
"""
        
        return context_info
    
    def _build_initial_prompt(
        self,
        execution_spec: Dict,
        context_info: str,
        test_data: Optional[pd.DataFrame],
        actual_columns: List[str],
        current_step: Dict = None
    ) -> str:
        """æ„å»ºåˆå§‹æç¤º"""
        
        # ä»åŸå§‹æ­¥éª¤ä¸­æå–è¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_files_info = ""
        input_data_info = ""
        
        if current_step and 'implementation_config' in current_step:
            config = current_step['implementation_config']
            
            # è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
            if 'output_files' in config:
                output_files = config['output_files']
                results_columns = output_files.get('results_columns', [])
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤šåˆ—éœ€è¦å±•å¼€ï¼ˆå¦‚ keyword_0, keyword_1...ï¼‰
                needs_expansion = len(results_columns) > 1 and any('_' in col for col in results_columns)
                
                output_files_info = f"""
**âš ï¸ é‡è¦ï¼šå¿…é¡»ä½¿ç”¨ä»¥ä¸‹æ–‡ä»¶è·¯å¾„ä¿å­˜ç»“æœ**
- ç»“æœCSV: `{output_files.get('results_csv', 'outputs/results.csv')}`
- ç»“æœåˆ—å: {results_columns}
- åˆ—æ•°æ®ç±»å‹: {output_files.get('column_types', {})}
- æ¨¡å‹PKL: `{output_files.get('model_pkl', 'outputs/model.pkl') if output_files.get('model_pkl') else 'æ— éœ€ä¿å­˜æ¨¡å‹'}`

"""
                if needs_expansion:
                    # æ„å»ºç¤ºä¾‹ä»£ç ï¼Œé¿å… f-string è½¬ä¹‰é—®é¢˜
                    example_columns = str(results_columns)
                    output_files_info += f"""
**ğŸ”¥ ç‰¹åˆ«æ³¨æ„ï¼šç»“æœéœ€è¦å±•å¼€æˆ {len(results_columns)} åˆ—ï¼**

å¦‚æœä½ çš„åˆ†æç”Ÿæˆäº†åˆ—è¡¨æ•°æ®ï¼ˆå¦‚æ¯ä¸ªæ–‡æ¡£çš„å¤šä¸ªå…³é”®è¯ï¼‰ï¼Œå¿…é¡»å±•å¼€æˆå¤šåˆ—ï¼š

âŒ é”™è¯¯åšæ³•ï¼ˆå•åˆ—åŒ…å«åˆ—è¡¨å­—ç¬¦ä¸²ï¼‰ï¼š
```python
results_df = pd.DataFrame({{'keywords': [['è¯1', 'è¯2'], ['è¯3', 'è¯4']]}}
# ä¿å­˜åï¼škeywords åˆ—åŒ…å« "['è¯1', 'è¯2']" è¿™æ ·çš„å­—ç¬¦ä¸²
```

âœ… æ­£ç¡®åšæ³•ï¼ˆå±•å¼€æˆå¤šåˆ—ï¼‰ï¼š
```python
# å‡è®¾ keywords_list = [['è¯1', 'è¯2', 'è¯3'], ['è¯4', 'è¯5', 'è¯6'], ...]
results_dict = {{}}
for i, col_name in enumerate({example_columns}):
    results_dict[col_name] = [doc[i] if len(doc) > i else '' for doc in keywords_list]
results_df = pd.DataFrame(results_dict)
# ä¿å­˜åï¼škeyword_0, keyword_1, keyword_2 ä¸‰åˆ—ï¼Œæ¯åˆ—ä¸€ä¸ªå…³é”®è¯
```

"""
                
                if 'format_notes' in output_files:
                    output_files_info += f"**ğŸ“‹ æ•°æ®æ ¼å¼è¦æ±‚ï¼š**\n{output_files['format_notes']}\n\n"
                
                # æ„å»ºåˆ—åå­—ç¬¦ä¸²ï¼Œé¿å… f-string è½¬ä¹‰é—®é¢˜
                columns_str = str(results_columns)
                output_files_info += f"""
**ğŸš¨ å…³é”®è¦æ±‚ï¼šåªä¿å­˜å¿…è¦çš„åˆ—ï¼**

ä¿å­˜ç»“æœæ—¶ï¼Œå¿…é¡»åªåŒ…å«ä»¥ä¸‹åˆ—ï¼š
1. ID åˆ—ï¼š`åºå·`, `å…¬å¼€(å…¬å‘Š)å·`ï¼ˆç”¨äºåç»­åˆå¹¶ï¼‰
2. æ–°ç”Ÿæˆçš„åˆ—ï¼š{columns_str}

âŒ ä¸è¦ä¿å­˜åŸå§‹æ•°æ®åˆ—ï¼ˆå¦‚æ ‡é¢˜ã€æ‘˜è¦ç­‰é•¿æ–‡æœ¬ï¼‰
âŒ ä¸è¦ä¿å­˜æ•´ä¸ª DataFrame
âŒ ä¸è¦ä¿å­˜ Python å¯¹è±¡ï¼ˆå¦‚ Timestampã€åˆ—è¡¨ï¼‰

âœ… æ­£ç¡®çš„æ•°æ®ç±»å‹ï¼š
- æ•°å€¼ï¼šint, float
- æ–‡æœ¬ï¼šstr
- æ—¥æœŸï¼šè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆå¦‚ '2023-01-01'ï¼‰

âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
```python
# åªé€‰æ‹© ID åˆ—å’Œæ–°ç”Ÿæˆçš„åˆ—
results_df = df[['åºå·', 'å…¬å¼€(å…¬å‘Š)å·'] + {columns_str}]
results_df.to_csv('æŒ‡å®šè·¯å¾„', index=False)
```

**ä»£ç ä¸­å¿…é¡»ä½¿ç”¨è¿™äº›ç²¾ç¡®çš„è·¯å¾„å’Œåˆ—åï¼**
"""
            
            # è¾“å…¥æ•°æ®ä¿¡æ¯
            if 'input_data_source' in config:
                input_source = config['input_data_source']
                input_data_info = f"""
**ğŸ“¥ è¾“å…¥æ•°æ®æºï¼ˆå¿…é¡»ä¸¥æ ¼éµå¾ªï¼‰ï¼š**
- ä¸»æ•°æ®æ–‡ä»¶: `{input_source.get('main_data', '')}`
- éœ€è¦çš„ä¸»æ•°æ®åˆ—: {input_source.get('main_data_columns', [])}

"""
                dependencies = input_source.get('dependencies', [])
                if dependencies:
                    input_data_info += """**ä¾èµ–çš„å‰ç½®æ­¥éª¤ç»“æœï¼š**
å‰ç½®æ­¥éª¤çš„ç»“æœæ–‡ä»¶åªåŒ…å« ID åˆ—å’Œæ–°ç”Ÿæˆçš„åˆ—ï¼Œéœ€è¦é€šè¿‡ ID ä¸ä¸»æ•°æ®åˆå¹¶ï¼

"""
                    for dep in dependencies:
                        input_data_info += f"- æ–‡ä»¶: `{dep.get('file', '')}`\n"
                        input_data_info += f"  éœ€è¦çš„åˆ—: {dep.get('columns', [])}\n"
                        input_data_info += f"  è¯´æ˜: {dep.get('description', '')}\n"
                    
                    input_data_info += """
**âš ï¸ æ­£ç¡®çš„åŠ è½½æ–¹å¼ï¼š**
```python
# 1. åŠ è½½ä¸»æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰åŸå§‹åˆ—ï¼‰
df = pd.read_excel('ä¸»æ•°æ®æ–‡ä»¶è·¯å¾„', sheet_name='clear')

# 2. åŠ è½½ä¾èµ–æ–‡ä»¶ï¼ˆåªåŒ…å« ID + æ–°åˆ—ï¼‰
dep_df = pd.read_csv('ä¾èµ–æ–‡ä»¶è·¯å¾„')
# dep_df ç»“æ„ï¼šåºå·, å…¬å¼€(å…¬å‘Š)å·, æ–°ç”Ÿæˆçš„åˆ—...

# 3. é€šè¿‡ ID åˆå¹¶ï¼ˆä¿ç•™ä¸»æ•°æ®çš„æ‰€æœ‰åˆ—ï¼‰
df = pd.merge(df, dep_df, on=['åºå·', 'å…¬å¼€(å…¬å‘Š)å·'], how='left')
# ç°åœ¨ df åŒ…å«ï¼šåŸå§‹æ•°æ® + ä¾èµ–æ­¥éª¤çš„ç»“æœåˆ—
```

è¿™æ ·å¯ä»¥åŒæ—¶è®¿é—®åŸå§‹æ•°æ®å’Œå‰ç½®æ­¥éª¤çš„ç»“æœï¼
"""
        
        # è·å–ç³»ç»Ÿä¿¡æ¯
        import getpass
        import platform
        
        system_info = f"""
**æ‰§è¡Œç¯å¢ƒï¼š**
- æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}
- Pythonç‰ˆæœ¬: {platform.python_version()}
- å·¥ä½œç›®å½•: {Path.cwd()}
"""
        
        prompt = f"""ä½ æ˜¯ä¸–ç•Œçº§çš„ Python æ•°æ®åˆ†æä¸“å®¶ï¼Œèƒ½å¤Ÿé€šè¿‡æ‰§è¡Œä»£ç å®Œæˆä»»ä½•æ•°æ®åˆ†æä»»åŠ¡ã€‚

**ä½ çš„èƒ½åŠ›ï¼š**
- âœ… ä½ æœ‰å®Œæ•´çš„æƒé™æ‰§è¡Œä»»ä½•å¿…è¦çš„ä»£ç 
- âœ… ä½ å¯ä»¥å®‰è£…æ–°çš„PythonåŒ…
- âœ… ä½ å¯ä»¥è®¿é—®æ–‡ä»¶ç³»ç»Ÿå’Œæ‰§è¡ŒShellå‘½ä»¤
- âœ… ä½ èƒ½å¤Ÿå®Œæˆä»»ä½•æ•°æ®åˆ†æä»»åŠ¡

**æ ¸å¿ƒåŸåˆ™ï¼ˆæ¥è‡ªä¸–ç•Œé¡¶çº§ç¼–ç¨‹å®è·µï¼‰ï¼š**
1. **å°æ­¥å¿«è·‘**ï¼šæ°¸è¿œä¸è¦è¯•å›¾åœ¨ä¸€ä¸ªä»£ç å—ä¸­å®Œæˆæ‰€æœ‰äº‹æƒ…
2. **æ‰“å°éªŒè¯**ï¼šæ¯ä¸€æ­¥éƒ½è¦æ‰“å°ä¿¡æ¯ï¼Œç¡®è®¤ç»“æœ
3. **æŒç»­è¿­ä»£**ï¼šç¬¬ä¸€æ¬¡å¾ˆå°‘æˆåŠŸï¼Œä»å°æ­¥éª¤ä¸­å­¦ä¹ å¹¶ç»§ç»­
4. **å¤±è´¥é‡è¯•**ï¼šå¦‚æœå¤±è´¥äº†ï¼Œåˆ†æé”™è¯¯ï¼Œè°ƒæ•´ç­–ç•¥ï¼Œå†è¯•ä¸€æ¬¡

{system_info}

ğŸš¨ **æœ€é‡è¦çš„è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š**

1. **ä¿å­˜ç»“æœæ—¶åªåŒ…å«å¿…è¦çš„åˆ—**
   - å¿…é¡»åŒ…å«ï¼šID åˆ—ï¼ˆ`åºå·`, `å…¬å¼€(å…¬å‘Š)å·`ï¼‰+ æ–°ç”Ÿæˆçš„åˆ—
   - ç¦æ­¢åŒ…å«ï¼šåŸå§‹æ•°æ®åˆ—ï¼ˆæ ‡é¢˜ã€æ‘˜è¦ç­‰ï¼‰ã€å‰ç½®æ­¥éª¤çš„åˆ—
   
2. **å¤šå€¼æ•°æ®å¿…é¡»å±•å¼€æˆå¤šåˆ—**
   - å¦‚æœç”Ÿæˆäº†åˆ—è¡¨æ•°æ®ï¼ˆå¦‚å…³é”®è¯åˆ—è¡¨ï¼‰ï¼Œå¿…é¡»å±•å¼€æˆç‹¬ç«‹çš„åˆ—
   - ç¦æ­¢ä¿å­˜ä¸ºå•åˆ—çš„åˆ—è¡¨å­—ç¬¦ä¸²

ğŸ“‹ **æ‰§è¡Œè§„æ ¼ï¼š**
{json.dumps(execution_spec, indent=2, ensure_ascii=False)}

{context_info}
{input_data_info}
{output_files_info}

ğŸ› ï¸ **ä½ çš„å·¥å…·ç®±ï¼š**
1. `run_python(code)` - æ‰§è¡Œ Python ä»£ç ï¼ˆæœ‰çŠ¶æ€ï¼Œå˜é‡ä¼šä¿æŒï¼‰
   - æŸ¥çœ‹æ•°æ®ï¼šrun_python("print(df.head())")
   - æŸ¥çœ‹åˆ—åï¼šrun_python("print(df.columns)")
   - æŸ¥çœ‹æ•°æ®ç±»å‹ï¼šrun_python("print(df.dtypes)")
2. `execute_shell(command)` - æ‰§è¡Œç»ˆç«¯å‘½ä»¤ï¼ˆls, mkdir, pip install ç­‰ï¼‰
3. `read_file(filepath)` - è¯»å–æ–‡ä»¶å†…å®¹
4. `write_file(filepath, content)` - å†™å…¥æ–‡ä»¶
5. `check_file_exists(filepath)` - æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨

ğŸ¯ **ä½ çš„ä»»åŠ¡æµç¨‹ï¼š**

**ç¬¬1æ­¥ï¼šç¯å¢ƒå‡†å¤‡**
- ä½¿ç”¨ `execute_shell` æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨
- å¦‚æœä¸å­˜åœ¨ï¼Œä½¿ç”¨ `execute_shell('mkdir outputs')` åˆ›å»º
- ä½¿ç”¨ `check_file_exists` æ£€æŸ¥ä¾èµ–æ–‡ä»¶æ˜¯å¦å­˜åœ¨

**ç¬¬2æ­¥ï¼šæ•°æ®æ¢ç´¢**
- ä½¿ç”¨ `run_python("print(df.head())")` æŸ¥çœ‹æ•°æ®
- ä½¿ç”¨ `run_python("print(df.columns)")` æŸ¥çœ‹åˆ—å
- äº†è§£å®é™…åˆ—åï¼š{actual_columns}

**ç¬¬3æ­¥ï¼šç¼–å†™å’Œæµ‹è¯•ä»£ç **
- ä½¿ç”¨ `run_python` é€æ­¥ç¼–å†™ä»£ç 
- å…ˆåŠ è½½æ•°æ®ï¼Œæ‰“å°ç¡®è®¤
- å†æ‰§è¡Œåˆ†æï¼Œæ‰“å°ä¸­é—´ç»“æœ
- æœ€åä¿å­˜ç»“æœåˆ°æŒ‡å®šè·¯å¾„

**ç¬¬4æ­¥ï¼šéªŒè¯ç»“æœ**
- ä½¿ç”¨ `check_file_exists` ç¡®è®¤æ–‡ä»¶å·²ä¿å­˜
- ä½¿ç”¨ `read_file` æŸ¥çœ‹å‰å‡ è¡Œï¼Œç¡®è®¤æ ¼å¼æ­£ç¡®
- **éªŒè¯åˆ—æ•°**ï¼šç¡®ä¿åªæœ‰ ID åˆ— + æ–°ç”Ÿæˆçš„åˆ—

âš ï¸ **å…³é”®è¦æ±‚ï¼ˆåŸºäºOpen Interpreteræœ€ä½³å®è·µï¼‰ï¼š**

1. **å°æ­¥æ‰§è¡Œï¼ŒæŒç»­éªŒè¯**
   - ğŸš« ä¸è¦è¯•å›¾ä¸€æ¬¡æ€§å®Œæˆæ‰€æœ‰ä»£ç 
   - âœ… å†™ä¸€å°æ®µï¼Œæ‰§è¡Œï¼Œæ‰“å°ç»“æœï¼Œè§‚å¯Ÿï¼Œå†ç»§ç»­
   - âœ… æ¯ä¸ªä»£ç å—åº”è¯¥åªåšä¸€ä»¶äº‹
   - ğŸ’¡ ä½ æ°¸è¿œä¸ä¼šç¬¬ä¸€æ¬¡å°±æˆåŠŸï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼

2. **å¿…é¡»æ‰“å°ä¸­é—´ç»“æœ**
   - æ¯æ¬¡ `run_python` éƒ½è¦ç”¨ print() æŸ¥çœ‹ç»“æœ
   - æ‰“å°æ•°æ®å½¢çŠ¶ã€åˆ—åã€å‰å‡ è¡Œã€ç»Ÿè®¡ä¿¡æ¯
   - è¿™æ ·ä½ æ‰èƒ½çŸ¥é“ä¸‹ä¸€æ­¥è¯¥åšä»€ä¹ˆ

3. **ä½¿ç”¨å®é™…åˆ—å**ï¼š{actual_columns}

4. **ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„**ï¼šä¸¥æ ¼ä½¿ç”¨ä¸Šé¢æŒ‡å®šçš„æ–‡ä»¶è·¯å¾„

5. **ğŸ”¥ åªä¿å­˜å¿…è¦çš„åˆ—**
   - å¿…é¡»åŒ…å«ï¼šID åˆ—ï¼ˆ`åºå·`, `å…¬å¼€(å…¬å‘Š)å·`ï¼‰+ æ–°ç”Ÿæˆçš„åˆ—
   - ç¦æ­¢åŒ…å«ï¼šåŸå§‹æ•°æ®åˆ—ã€å‰ç½®æ­¥éª¤çš„åˆ—

6. **å¤„ç†ä¾èµ–**ï¼šå¦‚æœéœ€è¦å‰ä¸€æ­¥çš„ç»“æœï¼Œå…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå†åŠ è½½

7. **é‡åˆ°é”™è¯¯æ—¶**
   - ä»”ç»†é˜…è¯»é”™è¯¯ä¿¡æ¯
   - æ‰“å°ç›¸å…³å˜é‡çš„å€¼å’Œç±»å‹
   - è°ƒæ•´ä»£ç ï¼Œå†è¯•ä¸€æ¬¡
   - å¦‚æœåŒæ ·çš„æ–¹æ³•å¤±è´¥å¤šæ¬¡ï¼Œæ¢ä¸€ä¸ªå®Œå…¨ä¸åŒçš„æ–¹æ³•

ğŸ“ **ä»£ç æ‰§è¡Œæ¨¡å¼ï¼ˆå°æ­¥å¿«è·‘ï¼‰ï¼š**

```python
# âŒ é”™è¯¯ç¤ºä¾‹ï¼šè¯•å›¾ä¸€æ¬¡å®Œæˆæ‰€æœ‰äº‹æƒ…
# è¿™æ ·åšä½ çœ‹ä¸åˆ°ä¸­é—´ç»“æœï¼Œå‡ºé”™äº†ä¹Ÿä¸çŸ¥é“å“ªé‡Œé”™äº†
df = pd.read_excel('data.xlsx')
df['new_col'] = some_complex_operation(df)
results = analyze(df)
results.to_csv('output.csv')
```

```python
# âœ… æ­£ç¡®ç¤ºä¾‹ï¼šå°æ­¥æ‰§è¡Œï¼Œæ¯æ­¥éªŒè¯

# æ­¥éª¤1ï¼šåŠ è½½æ•°æ®
import pandas as pd
df = pd.read_excel('data.xlsx')
print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape}")
print(f"åˆ—å: {list(df.columns)}")
```

```python
# æ­¥éª¤2ï¼šæŸ¥çœ‹æ•°æ®
print("å‰5è¡Œæ•°æ®:")
print(df.head())
print("\næ•°æ®ç±»å‹:")
print(df.dtypes)
```

```python
# æ­¥éª¤3ï¼šæ‰§è¡Œä¸€å°éƒ¨åˆ†åˆ†æ
# å…ˆåœ¨ä¸€ä¸ªæ ·æœ¬ä¸Šæµ‹è¯•
sample = df.head(10)
result = some_operation(sample)
print(f"æ ·æœ¬ç»“æœ: {result}")
# çœ‹èµ·æ¥æ­£ç¡®ï¼Œå†åº”ç”¨åˆ°å…¨éƒ¨æ•°æ®
```

```python
# æ­¥éª¤4ï¼šåº”ç”¨åˆ°å…¨éƒ¨æ•°æ®
df['new_col'] = some_operation(df)
print(f"âœ… æ–°åˆ—ç”Ÿæˆå®Œæˆ")
print(f"æ–°åˆ—çš„ç»Ÿè®¡: {df['new_col'].describe()}")
```

```python
# æ­¥éª¤5ï¼šä¿å­˜ç»“æœï¼ˆåªä¿å­˜å¿…è¦çš„åˆ—ï¼‰
results_df = df[['åºå·', 'å…¬å¼€(å…¬å‘Š)å·', 'new_col']]
results_df.to_csv('output.csv', index=False)
print(f"âœ… ç»“æœå·²ä¿å­˜: {results_df.shape}")
```

**ä¸ºä»€ä¹ˆè¦è¿™æ ·åšï¼Ÿ**
- ä½ èƒ½çœ‹åˆ°æ¯ä¸€æ­¥çš„ç»“æœ
- å‡ºé”™æ—¶èƒ½ç«‹å³å‘ç°é—®é¢˜åœ¨å“ª
- å¯ä»¥æ ¹æ®ä¸­é—´ç»“æœè°ƒæ•´ç­–ç•¥
- æ›´å®¹æ˜“è°ƒè¯•å’Œä¿®å¤

**è®°ä½ï¼šä½ æ˜¯åœ¨æ¢ç´¢å’Œå­¦ä¹ ï¼Œä¸æ˜¯åœ¨æ‰§è¡Œé¢„å®šçš„è„šæœ¬ï¼**

```python
# æ­¥éª¤2ï¼šåŠ è½½ä¾èµ–æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
prev_results = pd.read_csv('outputs/step_1_topic_results.csv')
print(f"å‰ç½®ç»“æœåŠ è½½æˆåŠŸ: {{prev_results.shape}}")
print(f"åˆ—å: {{list(prev_results.columns)}}")

# åˆå¹¶æ•°æ®ï¼ˆé€šè¿‡ ID åˆ—ï¼‰
# âš ï¸ å‰ç½®ç»“æœåªåŒ…å« ID + æ–°åˆ—ï¼Œéœ€è¦ä¸ä¸»æ•°æ®åˆå¹¶æ‰èƒ½è®¿é—®åŸå§‹åˆ—
df = pd.merge(df, prev_results, on=['åºå·', 'å…¬å¼€(å…¬å‘Š)å·'], how='left')
print(f"åˆå¹¶å: {{df.shape}}")
print(f"ç°åœ¨å¯ä»¥åŒæ—¶è®¿é—®åŸå§‹æ•°æ®å’Œå‰ç½®æ­¥éª¤çš„ç»“æœ")
```

```python
# æ­¥éª¤3ï¼šæ‰§è¡Œåˆ†æ
# ... ä½ çš„åˆ†æä»£ç  ...
print("åˆ†æå®Œæˆ")
```

```python
# æ­¥éª¤4ï¼šä¿å­˜ç»“æœ
import joblib

# âš ï¸ é‡è¦ï¼šåªä¿å­˜ ID åˆ—å’Œæ–°ç”Ÿæˆçš„åˆ—ï¼
# 
# âŒ é”™è¯¯ç¤ºä¾‹ï¼š
# df.to_csv('path.csv')  # ä¿å­˜äº†æ‰€æœ‰åˆ—ï¼ŒåŒ…æ‹¬åŸå§‹æ•°æ®
# results_df = pd.DataFrame({{'keywords': keywords_list}})  # å•åˆ—åŒ…å«åˆ—è¡¨
#
# âœ… æ­£ç¡®ç¤ºä¾‹ï¼š
# results_df = df[['åºå·', 'å…¬å¼€(å…¬å‘Š)å·', 'new_col1', 'new_col2']]  # åªé€‰æ‹©å¿…è¦çš„åˆ—
# 
# å¦‚æœæœ‰å¤šåˆ—éœ€è¦å±•å¼€ï¼ˆå¦‚ keyword_0, keyword_1...ï¼‰ï¼š
# results_dict = {{'åºå·': df['åºå·'], 'å…¬å¼€(å…¬å‘Š)å·': df['å…¬å¼€(å…¬å‘Š)å·']}}
# for i in range(5):
#     results_dict[f'keyword_{{i}}'] = [doc[i] if len(doc) > i else '' for doc in keywords_list]
# results_df = pd.DataFrame(results_dict)

# ç¤ºä¾‹ï¼šåªä¿å­˜ ID å’Œæ–°åˆ—
results_df = df[['åºå·', 'å…¬å¼€(å…¬å‘Š)å·', 'new_column1', 'new_column2']]
results_df.to_csv('æŒ‡å®šçš„è·¯å¾„', index=False)
print(f"ç»“æœå·²ä¿å­˜: {{results_df.shape}}")

# å¦‚æœæœ‰æ¨¡å‹
if 'model' in locals():
    joblib.dump(model, 'æŒ‡å®šçš„è·¯å¾„')
    print("æ¨¡å‹å·²ä¿å­˜")
```

```python
# æ­¥éª¤5ï¼šéªŒè¯ä¿å­˜çš„æ–‡ä»¶
import os
if os.path.exists('æŒ‡å®šçš„è·¯å¾„'):
    print(f"æ–‡ä»¶å­˜åœ¨")
    # è¯»å–å¹¶éªŒè¯åˆ—æ•°
    verify_df = pd.read_csv('æŒ‡å®šçš„è·¯å¾„')
    print(f"ä¿å­˜çš„åˆ—: {{list(verify_df.columns)}}")
    print(f"åˆ—æ•°: {{len(verify_df.columns)}}")
    print(f"å‰å‡ è¡Œ:")
    print(verify_df.head())
else:
    print(f"æ–‡ä»¶ä¸å­˜åœ¨")
```

**ğŸ¯ å®Œæˆæ ‡å‡†ï¼š**
å½“ä½ å®Œæˆä»¥ä¸‹æ‰€æœ‰æ­¥éª¤åï¼Œä»»åŠ¡å°±å®Œæˆäº†ï¼š
1. âœ… æ•°æ®å·²åŠ è½½
2. âœ… åˆ†æå·²å®Œæˆ
3. âœ… ç»“æœå·²ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
4. âœ… æ–‡ä»¶å·²éªŒè¯ï¼ˆåˆ—æ•°å’Œå†…å®¹æ­£ç¡®ï¼‰

**ğŸ›‘ åœæ­¢æ¡ä»¶ï¼ˆä½•æ—¶ä»»åŠ¡å®Œæˆï¼‰ï¼š**

å½“ä½ å®Œæˆä»¥ä¸‹æ‰€æœ‰æ­¥éª¤åï¼Œ**ç«‹å³è¿”å›æœ€ç»ˆç­”æ¡ˆå¹¶åœæ­¢**ï¼š
1. âœ… æ•°æ®å·²åŠ è½½å¹¶éªŒè¯
2. âœ… åˆ†æå·²å®Œæˆå¹¶æ‰“å°äº†ç»“æœ
3. âœ… ç»“æœå·²ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
4. âœ… æ–‡ä»¶å·²éªŒè¯ï¼ˆä½¿ç”¨read_fileæŸ¥çœ‹å‰å‡ è¡Œï¼Œç¡®è®¤åˆ—æ•°å’Œå†…å®¹æ­£ç¡®ï¼‰

**æœ€ç»ˆç­”æ¡ˆæ ¼å¼ï¼š**
```
âœ… ä»»åŠ¡å®Œæˆï¼

ç»“æœæ–‡ä»¶ï¼šoutputs/step_X_results.csv
æ•°æ®å½¢çŠ¶ï¼š(è¡Œæ•°, åˆ—æ•°)
ä¿å­˜çš„åˆ—ï¼š['åºå·', 'å…¬å¼€(å…¬å‘Š)å·', 'æ–°åˆ—1', 'æ–°åˆ—2']

éªŒè¯é€šè¿‡ï¼š
- æ–‡ä»¶å­˜åœ¨ âœ“
- åˆ—æ•°æ­£ç¡® âœ“
- æ•°æ®æ ¼å¼æ­£ç¡® âœ“
```

**âš ï¸ å®ŒæˆéªŒè¯åï¼Œä¸è¦æ‰§è¡Œä»»ä½•é¢å¤–çš„æµ‹è¯•ã€åˆ†ææˆ–æ¢ç´¢ä»£ç ï¼**

---

å¼€å§‹æ‰§è¡Œå§ï¼è®°ä½ï¼š
- ğŸ¢ å°æ­¥å¿«è·‘ï¼Œæ¯æ­¥éƒ½è¦printç¡®è®¤
- ğŸ”„ ç¬¬ä¸€æ¬¡å¤±è´¥æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­å°è¯•
- ğŸ¯ å®ŒæˆéªŒè¯åç«‹å³åœæ­¢å¹¶è¿”å›æœ€ç»ˆç­”æ¡ˆ
        
        return prompt
    
    def _extract_final_result(self, agent_result: Dict) -> Dict[str, Any]:
        """ä» agent ç»“æœä¸­æå–æœ€ç»ˆç»“æœ"""
        messages = agent_result.get("messages", [])
        
        generated_code = []
        last_tool_result = ""
        iteration_count = 0
        
        for msg in messages:
            content = msg.content if hasattr(msg, 'content') else str(msg)
            
            # æå–ä»£ç å—
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                for tool_call in msg.tool_calls:
                    if tool_call['name'] == 'run_python':
                        code = tool_call['args'].get('code', '')
                        if code:
                            generated_code.append(code)
                            iteration_count += 1
            
            # è®°å½•æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨çš„ç»“æœ
            if 'tool' in str(type(msg)).lower() or 'ToolMessage' in str(type(msg)):
                last_tool_result = content
        
        # åˆå¹¶æ‰€æœ‰ä»£ç å—
        full_code = "\n\n# ===== ä¸‹ä¸€æ­¥ =====\n\n".join(generated_code)
        
        # åˆ¤æ–­ä»£ç æ˜¯å¦æœ‰æ•ˆï¼š
        # 1. æœ‰ä»£ç ç”Ÿæˆ
        # 2. æœ€åçš„å·¥å…·ç»“æœä¸åŒ…å«é”™è¯¯æ ‡è®°
        # 3. å¦‚æœæœ€åä¸€ä¸ªå·¥å…·æ˜¯read_fileä¸”æˆåŠŸï¼Œè¯´æ˜å·²ç»éªŒè¯å®Œæˆ
        has_error = "âŒ" in last_tool_result or "Error" in last_tool_result or "Traceback" in last_tool_result
        has_verification = "âœ… [OK] è¯»å–æˆåŠŸ" in last_tool_result or "æ–‡ä»¶å­˜åœ¨" in last_tool_result
        is_code_valid = generated_code and not has_error
        
        # å¦‚æœå·²ç»éªŒè¯äº†ç»“æœæ–‡ä»¶ï¼Œè®¤ä¸ºä»»åŠ¡å®Œæˆ
        if has_verification and not has_error:
            is_code_valid = True
        
        return {
            'generated_code': full_code,
            'iteration_count': iteration_count,
            'is_code_valid': is_code_valid,
            'runtime_error': last_tool_result if has_error else '',
            'error_history': self.error_history
        }
    
    def _parse_error(self, error_msg: str) -> Tuple[str, str]:
        """è§£æé”™è¯¯ä¿¡æ¯"""
        for error_type in ERROR_FIX_PROMPTS.keys():
            if error_type in error_msg:
                lines = error_msg.strip().split("\n")
                detail = lines[-1] if lines else error_msg
                return error_type, detail
        
        return "UnknownError", error_msg[:200]
    
    def _is_repeated_error(self, error_type: str, threshold: int = 2) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤é”™è¯¯"""
        count = sum(1 for err in self.error_history if err['type'] == error_type)
        return count >= threshold
