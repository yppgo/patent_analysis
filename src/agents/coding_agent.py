"""
Coding Agent V2 - ç¼–ç æ™ºèƒ½ä½“
åŸºäº LangGraph create_react_agent çš„ç®€åŒ–å®ç°
"""

import json
import pandas as pd
from typing import Dict, Any, List
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import SystemMessage
from langchain_core.tools import tool
from src.agents.base_agent import BaseAgent


class CodingAgentV2(BaseAgent):
    """
    ç¼–ç æ™ºèƒ½ä½“ V2ï¼ˆæ‰§è¡Œè€…ï¼‰
    
    ä½¿ç”¨ LangGraph çš„ create_react_agent è‡ªåŠ¨ç®¡ç† ReAct æµç¨‹ï¼š
    - å·¥å…·ï¼šgenerate_code, test_code, check_code
    - LLM è‡ªåŠ¨å†³å®šå·¥å…·è°ƒç”¨é¡ºåºå’Œæ—¶æœº
    
    æ ¸å¿ƒåˆ›æ–°ï¼šè¿è¡Œæ—¶æµ‹è¯• + è‡ªåŠ¨ä¿®å¤
    """
    
    def __init__(self, llm_client, test_data=None, max_iterations=3, logger=None):
        """
        åˆå§‹åŒ– Coding Agent V2
        
        Args:
            llm_client: LLM å®¢æˆ·ç«¯
            test_data: æµ‹è¯•æ•°æ®ï¼ˆDataFrameï¼‰
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            logger: æ—¥å¿—è®°å½•å™¨
        """
        super().__init__("CodingAgentV2", llm_client, logger)
        self.test_data = test_data
        self.max_iterations = max_iterations
        
        # å­˜å‚¨å½“å‰æ‰§è¡Œä¸Šä¸‹æ–‡
        self.current_execution_spec = None
        self.current_test_data = None
        self.iteration_count = 0
        self.generated_code = ""
        self.execution_result = None
        
        # åˆ›å»ºå·¥å…·å’Œ agent
        self.tools = self._create_tools()
        self.agent = self._build_agent()
    
    def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†æ‰§è¡Œè§„æ ¼ï¼Œç”Ÿæˆé«˜è´¨é‡ä»£ç 
        
        Args:
            input_data: {
                "execution_spec": {...},
                "current_step": {...},
                "test_data": DataFrame (å¯é€‰)
            }
            
        Returns:
            {
                "generated_code": str,
                "iteration_count": int,
                "is_code_valid": bool,
                "code_issues": List[str],
                "runtime_error": str,
                "execution_result": Dict (å¯é€‰)
            }
        """
        execution_spec = input_data.get('execution_spec', {})
        test_data = input_data.get('test_data', self.test_data)
        
        # è®¾ç½®æ‰§è¡Œä¸Šä¸‹æ–‡
        self.current_execution_spec = execution_spec
        self.current_test_data = test_data
        self.iteration_count = 0
        self.generated_code = ""
        self.execution_result = None
        
        func_name = execution_spec.get('function_name', 'N/A')
        print(f"\n{'='*60}")
        print(f"å¼€å§‹ç”Ÿæˆä»£ç : {func_name}")
        print(f"{'='*60}")
        self.log(f"å¼€å§‹ç”Ÿæˆä»£ç : {func_name}")
        
        # æ„å»ºåˆå§‹æ¶ˆæ¯ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºå’Œæ•°æ®é¢„è§ˆï¼‰
        has_test_data = test_data is not None and len(test_data) > 0
        
        # ç”Ÿæˆæ•°æ®é¢„è§ˆ
        data_preview = ""
        if has_test_data:
            data_preview = f"""
æ•°æ®é¢„è§ˆï¼š
- æ•°æ®å½¢çŠ¶: {test_data.shape[0]} è¡Œ Ã— {test_data.shape[1]} åˆ—
- åˆ—å: {list(test_data.columns)}
- æ•°æ®ç±»å‹: {dict(test_data.dtypes.astype(str))}
- å‰3è¡Œæ ·æœ¬:
{test_data.head(3).to_string()}

é‡è¦æç¤ºï¼š
- æ•°æ®å·²ç»åŠ è½½åœ¨å˜é‡ df ä¸­
- è¯·æ ¹æ®å®é™…çš„åˆ—åç¼–å†™ä»£ç 
- ä½¿ç”¨ df.iloc[i] è®¿é—®è¡Œï¼Œä½¿ç”¨ df['åˆ—å'] è®¿é—®åˆ—
"""
        
        initial_message = f"""ä½ æ˜¯ä¸“ä¸šçš„ Python ä»£ç ç”Ÿæˆä¸“å®¶ã€‚

è¯·æ ¹æ®ä»¥ä¸‹æ‰§è¡Œè§„æ ¼ç”Ÿæˆé«˜è´¨é‡çš„ Python ä»£ç ï¼š

æ‰§è¡Œè§„æ ¼ï¼š
{json.dumps(execution_spec, indent=2, ensure_ascii=False)}
{data_preview}
æµ‹è¯•æ•°æ®çŠ¶æ€ï¼š{'âœ… å·²æä¾›æµ‹è¯•æ•°æ®ï¼Œå¿…é¡»è¿›è¡Œè¿è¡Œæ—¶æµ‹è¯•' if has_test_data else 'âŒ æ— æµ‹è¯•æ•°æ®ï¼Œåªè¿›è¡Œé™æ€æ£€æŸ¥'}

å·¥ä½œæµç¨‹ï¼š
1. ä½¿ç”¨ generate_code å·¥å…·ç”Ÿæˆä»£ç 
2. ä½¿ç”¨ check_code å·¥å…·è¿›è¡Œé™æ€æ£€æŸ¥
3. {'ä½¿ç”¨ test_code å·¥å…·è¿›è¡Œè¿è¡Œæ—¶æµ‹è¯•ï¼ˆå¿…é¡»æ‰§è¡Œï¼‰' if has_test_data else 'è·³è¿‡è¿è¡Œæ—¶æµ‹è¯•ï¼ˆæ— æµ‹è¯•æ•°æ®ï¼‰'}
4. å¦‚æœå‘ç°é—®é¢˜ï¼Œä½¿ç”¨ generate_code é‡æ–°ç”Ÿæˆï¼ˆä¼ å…¥é—®é¢˜æè¿°ï¼‰
5. é‡å¤ç›´åˆ°ä»£ç é€šè¿‡æ‰€æœ‰æ£€æŸ¥æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°

æ³¨æ„ï¼š
- æœ€å¤šè¿­ä»£ {self.max_iterations} æ¬¡
- ä¼˜å…ˆä¿®å¤è¿è¡Œæ—¶é”™è¯¯
- ç¡®ä¿ä»£ç æœ‰å®Œæ•´çš„é”™è¯¯å¤„ç†
- {'å¿…é¡»è°ƒç”¨ test_code å·¥å…·æµ‹è¯•ä»£ç ' if has_test_data else 'æ— éœ€è¿è¡Œæ—¶æµ‹è¯•'}

è¯·ä¸¥æ ¼æŒ‰ç…§å·¥ä½œæµç¨‹æ‰§è¡Œï¼Œä¸è¦è·³è¿‡ä»»ä½•æ­¥éª¤ï¼"""
        
        # è°ƒç”¨ agent
        result = self.agent.invoke({
            "messages": [("user", initial_message)]
        })
        
        # ä»æ¶ˆæ¯å†å²ä¸­æå–ç»“æœ
        final_result = self._extract_final_result(result)
        
        print(f"\n{'='*60}")
        print(f"ä»£ç ç”Ÿæˆå®Œæˆ: è¿­ä»£ {self.iteration_count} æ¬¡")
        print(f"ä»£ç æœ‰æ•ˆ: {final_result['is_code_valid']}")
        print(f"{'='*60}\n")
        self.log(f"ä»£ç ç”Ÿæˆå®Œæˆ: è¿­ä»£ {self.iteration_count} æ¬¡")
        
        return final_result
    
    def _create_tools(self) -> List:
        """åˆ›å»ºå·¥å…·åˆ—è¡¨"""
        
        # ä¿å­˜ self å¼•ç”¨
        agent_self = self
        
        @tool
        def generate_code(issues_to_fix: str = "") -> str:
            """
            ç”Ÿæˆ Python ä»£ç 
            
            Args:
                issues_to_fix: éœ€è¦ä¿®å¤çš„é—®é¢˜æè¿°ï¼ˆå¯é€‰ï¼‰
            
            Returns:
                ç”Ÿæˆçš„ä»£ç 
            """
            print(f"\nâš¡ [å·¥å…·] ç”Ÿæˆä»£ç ... (ç¬¬ {agent_self.iteration_count + 1} æ¬¡)")
            agent_self.log("âš¡ [å·¥å…·] ç”Ÿæˆä»£ç ...")
            agent_self.iteration_count += 1
            
            if agent_self.iteration_count > agent_self.max_iterations:
                msg = f"å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° ({agent_self.max_iterations})ï¼Œåœæ­¢ç”Ÿæˆ"
                print(f"  âš ï¸ {msg}")
                return msg
            
            execution_spec = agent_self.current_execution_spec
            
            prompt = f"""ä½ æ˜¯ Python å·¥ç¨‹å¸ˆã€‚ç”Ÿæˆä»£ç ã€‚

**æ‰§è¡Œè§„æ ¼:**
{json.dumps(execution_spec, indent=2, ensure_ascii=False)}
"""
            
            if issues_to_fix:
                prompt += f"""
**éœ€è¦ä¿®å¤çš„é—®é¢˜:**
{issues_to_fix}

**è¯·ç‰¹åˆ«æ³¨æ„ä¿®å¤è¿™äº›é—®é¢˜ï¼**
"""
            
            prompt += f"""
**ä»£ç è¦æ±‚:**
1. å‡½æ•°ç­¾åå¿…é¡»æ˜¯: def {execution_spec.get('function_name', 'analyze')}(df: pd.DataFrame) -> Dict[str, Any]
2. å¿…é¡»æœ‰å®Œæ•´çš„ç±»å‹æ³¨è§£å’Œä¸­æ–‡æ³¨é‡Š
3. å¿…é¡»æœ‰ try-except é”™è¯¯å¤„ç†
4. ä½¿ç”¨ df.iloc[i] è€Œä¸æ˜¯ df.loc[i]
5. ä¸è¦åŒ…å«ä»»ä½• import è¯­å¥
6. åªè¾“å‡ºå‡½æ•°ä»£ç ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹

**é‡è¦**: ç›´æ¥è¾“å‡ºå‡½æ•°ä»£ç ï¼Œä¸è¦ç”¨ markdown ä»£ç å—åŒ…è£¹ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šæ–‡å­—ã€‚"""
            
            try:
                response = agent_self.llm.invoke(prompt)
                code = agent_self._extract_code(response.content if hasattr(response, 'content') else str(response))
                agent_self.generated_code = code
                lines = len(code.split(chr(10)))
                print(f"  âœ“ ä»£ç ç”ŸæˆæˆåŠŸ ({lines} è¡Œ)")
                agent_self.log(f"  âœ“ ä»£ç ç”ŸæˆæˆåŠŸ ({lines} è¡Œ)")
                return code
            except Exception as e:
                print(f"  âš ï¸ ä»£ç ç”Ÿæˆå¤±è´¥: {e}")
                agent_self.log(f"  âš ï¸ ä»£ç ç”Ÿæˆå¤±è´¥: {e}", "warning")
                return f"ä»£ç ç”Ÿæˆå¤±è´¥: {e}"
        
        @tool
        def test_code(code: str) -> str:
            """
            ä½¿ç”¨çœŸå®æ•°æ®æµ‹è¯•ä»£ç 
            
            Args:
                code: è¦æµ‹è¯•çš„ä»£ç 
            
            Returns:
                æµ‹è¯•ç»“æœï¼ˆæˆåŠŸæˆ–é”™è¯¯ä¿¡æ¯ï¼‰
            """
            print("\nğŸ§ª [å·¥å…·] è¿è¡Œæ—¶æµ‹è¯•...")
            agent_self.log("ğŸ§ª [å·¥å…·] è¿è¡Œæ—¶æµ‹è¯•...")
            
            test_data = agent_self.current_test_data
            if test_data is None or len(test_data) == 0:
                print("  âš ï¸ æ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡")
                agent_self.log("  âš ï¸ æ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡")
                return "æ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡è¿è¡Œæ—¶æµ‹è¯•"
            
            print(f"  ğŸ“Š ä½¿ç”¨ {len(test_data)} æ¡æ•°æ®æµ‹è¯•...")
            agent_self.log(f"  ğŸ“Š ä½¿ç”¨ {len(test_data)} æ¡æ•°æ®æµ‹è¯•...")
            
            try:
                exec_globals = agent_self._prepare_execution_environment(test_data)
                exec(code, exec_globals)
                
                func_name = agent_self.current_execution_spec.get('function_name', 'analyze')
                if func_name in exec_globals:
                    result = exec_globals[func_name](test_data)
                    
                    if isinstance(result, dict) and 'error' in result:
                        error_msg = result['error']
                        print(f"  âš ï¸ å‡½æ•°è¿”å›é”™è¯¯: {error_msg}")
                        agent_self.log(f"  âš ï¸ å‡½æ•°è¿”å›é”™è¯¯: {error_msg}")
                        return f"è¿è¡Œæ—¶é”™è¯¯: {error_msg}"
                    else:
                        print("  âœ… è¿è¡Œæ—¶æµ‹è¯•é€šè¿‡")
                        agent_self.log("  âœ… è¿è¡Œæ—¶æµ‹è¯•é€šè¿‡")
                        agent_self.execution_result = agent_self._serialize_result(result)
                        return "è¿è¡Œæ—¶æµ‹è¯•é€šè¿‡"
                else:
                    error_msg = f"å‡½æ•° {func_name} æœªæ‰¾åˆ°"
                    print(f"  âš ï¸ {error_msg}")
                    agent_self.log(f"  âš ï¸ {error_msg}")
                    return f"é”™è¯¯: {error_msg}"
            except Exception as e:
                error_msg = str(e)
                print(f"  âš ï¸ è¿è¡Œæ—¶é”™è¯¯: {error_msg}")
                agent_self.log(f"  âš ï¸ è¿è¡Œæ—¶é”™è¯¯: {error_msg}")
                return f"è¿è¡Œæ—¶é”™è¯¯: {error_msg}"
        
        @tool
        def check_code(code: str) -> str:
            """
            é™æ€æ£€æŸ¥ä»£ç è´¨é‡
            
            Args:
                code: è¦æ£€æŸ¥çš„ä»£ç 
            
            Returns:
                æ£€æŸ¥ç»“æœï¼ˆé—®é¢˜åˆ—è¡¨æˆ–"é€šè¿‡"ï¼‰
            """
            print("\nğŸ‘€ [å·¥å…·] é™æ€æ£€æŸ¥...")
            agent_self.log("ğŸ‘€ [å·¥å…·] é™æ€æ£€æŸ¥...")
            
            issues = agent_self._static_code_check(code, agent_self.current_execution_spec)
            
            if not issues:
                print("  âœ… é™æ€æ£€æŸ¥é€šè¿‡")
                agent_self.log("  âœ… é™æ€æ£€æŸ¥é€šè¿‡")
                return "é™æ€æ£€æŸ¥é€šè¿‡"
            else:
                print(f"  âš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜")
                agent_self.log(f"  âš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜")
                for issue in issues:
                    print(f"    - {issue}")
                    agent_self.log(f"    - {issue}")
                return "å‘ç°é—®é¢˜:\n" + "\n".join(f"- {issue}" for issue in issues)
        
        return [generate_code, test_code, check_code]
    
    def _build_agent(self):
        """ä½¿ç”¨ create_react_agent æ„å»º agent"""
        
        # è·å–åº•å±‚çš„ ChatOpenAI å®ä¾‹
        llm_instance = self.llm.get_llm() if hasattr(self.llm, 'get_llm') else self.llm
        
        # ä½¿ç”¨ create_react_agent åˆ›å»º agent
        # ç³»ç»Ÿæç¤ºä¼šåœ¨ process æ–¹æ³•ä¸­é€šè¿‡åˆå§‹æ¶ˆæ¯ä¼ é€’
        agent = create_react_agent(
            llm_instance,
            self.tools
        )
        
        return agent
    
    def _extract_final_result(self, agent_result: Dict) -> Dict[str, Any]:
        """ä» agent ç»“æœä¸­æå–æœ€ç»ˆç»“æœ"""
        messages = agent_result.get("messages", [])
        
        # æŸ¥æ‰¾æœ€åçš„å·¥å…·è°ƒç”¨ç»“æœ
        last_test_result = ""
        last_check_result = ""
        
        for msg in messages:
            content = msg.content if hasattr(msg, 'content') else str(msg)
            
            # è®°å½•æœ€åçš„æµ‹è¯•å’Œæ£€æŸ¥ç»“æœ
            if "è¿è¡Œæ—¶æµ‹è¯•é€šè¿‡" in content:
                last_test_result = "é€šè¿‡"
            elif "è¿è¡Œæ—¶é”™è¯¯" in content:
                last_test_result = content
            
            if "é™æ€æ£€æŸ¥é€šè¿‡" in content:
                last_check_result = "é€šè¿‡"
            elif "å‘ç°é—®é¢˜" in content:
                last_check_result = content
        
        # åˆ¤æ–­ä»£ç æ˜¯å¦æœ‰æ•ˆï¼šæœ€åçš„æ£€æŸ¥å’Œæµ‹è¯•éƒ½é€šè¿‡
        is_code_valid = (
            self.generated_code and
            last_check_result == "é€šè¿‡" and
            (last_test_result == "é€šè¿‡" or last_test_result == "")
        )
        
        # æå–é”™è¯¯ä¿¡æ¯
        runtime_error = last_test_result if last_test_result != "é€šè¿‡" and last_test_result != "" else ""
        code_issues = [last_check_result] if last_check_result != "é€šè¿‡" and last_check_result != "" else []
        
        return {
            'generated_code': self.generated_code,
            'iteration_count': self.iteration_count,
            'is_code_valid': is_code_valid,
            'code_issues': code_issues,
            'runtime_error': runtime_error,
            'execution_result': self.execution_result
        }

    def _extract_code(self, response: str) -> str:
        """ä»å“åº”ä¸­æå–ä»£ç """
        code = response.strip()
        
        if code.startswith("```"):
            lines = code.split("\n")
            code_lines = []
            in_code = False
            
            for line in lines:
                if line.startswith("```"):
                    in_code = not in_code
                    continue
                if in_code:
                    code_lines.append(line)
            
            code = "\n".join(code_lines)
        
        # ç§»é™¤ import è¯­å¥
        code_lines = code.split("\n")
        filtered_lines = []
        for line in code_lines:
            stripped = line.strip()
            if not (stripped.startswith("import ") or stripped.startswith("from ")):
                filtered_lines.append(line)
        
        return "\n".join(filtered_lines)
    
    def _static_code_check(self, code: str, execution_spec: Dict) -> List[str]:
        """é™æ€ä»£ç æ£€æŸ¥"""
        issues = []
        
        # åŸºæœ¬æ£€æŸ¥
        if not code or len(code.strip()) < 50:
            issues.append("ä»£ç ä¸ºç©ºæˆ–è¿‡çŸ­")
        
        func_name = execution_spec.get('function_name', 'analyze')
        if f"def {func_name}" not in code:
            issues.append(f"ç¼ºå°‘å‡½æ•°å®šä¹‰: {func_name}")
        
        if "return" not in code:
            issues.append("ç¼ºå°‘ return è¯­å¥")
        
        if "try:" not in code or "except" not in code:
            issues.append("ç¼ºå°‘é”™è¯¯å¤„ç†")
        
        if "Dict" not in code and "dict" not in code.lower():
            issues.append("ç¼ºå°‘è¿”å›ç±»å‹æ³¨è§£")
        
        # è¯­æ³•æ£€æŸ¥
        try:
            compile(code, '<string>', 'exec')
        except SyntaxError as e:
            issues.append(f"è¯­æ³•é”™è¯¯: {e}")
        
        return issues
    
    def _serialize_result(self, result: Any) -> Dict[str, Any]:
        """
        åºåˆ—åŒ–æ‰§è¡Œç»“æœï¼Œä½¿å…¶å¯ä»¥JSONåŒ–
        
        å¤„ç†å¸¸è§çš„æ•°æ®ç±»å‹ï¼š
        - DataFrame -> dict
        - numpy array -> list
        - å…¶ä»–å¤æ‚å¯¹è±¡ -> str
        """
        import numpy as np
        
        if result is None:
            return {'type': 'none', 'value': None}
        
        if isinstance(result, dict):
            serialized = {}
            for key, value in result.items():
                if isinstance(value, pd.DataFrame):
                    # DataFrameè½¬ä¸ºå­—å…¸ï¼Œä¿ç•™å‰100è¡Œ
                    serialized[key] = {
                        'type': 'dataframe',
                        'shape': value.shape,
                        'columns': list(value.columns),
                        'sample': value.head(100).to_dict('records')
                    }
                elif isinstance(value, (np.ndarray, list)):
                    # æ•°ç»„è½¬ä¸ºåˆ—è¡¨ï¼Œä¿ç•™å‰100ä¸ªå…ƒç´ 
                    arr = np.array(value) if not isinstance(value, np.ndarray) else value
                    serialized[key] = {
                        'type': 'array',
                        'shape': arr.shape if hasattr(arr, 'shape') else len(arr),
                        'sample': arr.flatten()[:100].tolist() if hasattr(arr, 'flatten') else list(value)[:100]
                    }
                elif isinstance(value, (int, float, str, bool)):
                    serialized[key] = value
                else:
                    # å…¶ä»–ç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²
                    serialized[key] = {
                        'type': 'object',
                        'value': str(value)[:500]  # é™åˆ¶é•¿åº¦
                    }
            return serialized
        else:
            # éå­—å…¸ç»“æœ
            return {
                'type': 'raw',
                'value': str(result)[:1000]
            }
    
    def _prepare_execution_environment(self, test_data):
        """å‡†å¤‡ä»£ç æ‰§è¡Œç¯å¢ƒ"""
        import numpy as np
        
        # å¯¼å…¥å¸¸ç”¨çš„åˆ†æåº“
        try:
            from pyod.models.abod import ABOD
        except ImportError:
            class MockABOD:
                def __init__(self, *args, **kwargs): pass
                def fit_predict(self, data): return [1] * len(data)
            ABOD = MockABOD
        
        try:
            from sentence_transformers import SentenceTransformer
        except ImportError:
            class MockSentenceTransformer:
                def __init__(self, *args, **kwargs): pass
                def encode(self, texts): return [[0.1] * 384] * len(texts)
            SentenceTransformer = MockSentenceTransformer
        
        # å¯¼å…¥gensimç›¸å…³
        try:
            from gensim import corpora
            from gensim.models import LdaModel
            from gensim.utils import simple_preprocess
        except ImportError:
            corpora = None
            LdaModel = None
            simple_preprocess = None
        
        # å¯¼å…¥nltkç›¸å…³
        try:
            from nltk.corpus import stopwords
        except ImportError:
            class MockStopwords:
                @staticmethod
                def words(lang): return []
            stopwords = MockStopwords()
        
        # å¯¼å…¥sklearnç›¸å…³
        try:
            from sklearn.cluster import DBSCAN
            from sklearn.feature_extraction.text import TfidfVectorizer
            from sklearn.metrics.pairwise import cosine_similarity
        except ImportError:
            DBSCAN = None
            TfidfVectorizer = None
            cosine_similarity = None
        
        # å¯¼å…¥å…¶ä»–å¸¸ç”¨åº“
        try:
            import re
        except ImportError:
            re = None
        
        return {
            'pd': pd,
            'np': np,
            'df': test_data,
            'Dict': Dict,
            'List': List,
            'Any': Any,
            'Tuple': tuple,
            # åˆ†æåº“
            'ABOD': ABOD,
            'SentenceTransformer': SentenceTransformer,
            'corpora': corpora,
            'LdaModel': LdaModel,
            'simple_preprocess': simple_preprocess,
            'stopwords': stopwords,
            'DBSCAN': DBSCAN,
            'TfidfVectorizer': TfidfVectorizer,
            'cosine_similarity': cosine_similarity,
            're': re,
            '__builtins__': __builtins__
        }
