"""
çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç¤ºä¾‹
æä¾›å¸¸ç”¨çš„ Cypher æŸ¥è¯¢ç¤ºä¾‹
"""

from neo4j import GraphDatabase
from neo4j_config import NEO4J_CONFIG
import json


class KnowledgeGraphQuery:
    """çŸ¥è¯†å›¾è°±æŸ¥è¯¢å·¥å…·"""
    
    def __init__(self):
        self.driver = GraphDatabase.driver(
            NEO4J_CONFIG["uri"],
            auth=(NEO4J_CONFIG["user"], NEO4J_CONFIG["password"])
        )
    
    def close(self):
        self.driver.close()
    
    def query_1_papers_by_intent(self, intent_name: str):
        """æŸ¥è¯¢ä½¿ç”¨ç‰¹å®šæ„å›¾çš„æ‰€æœ‰è®ºæ–‡"""
        print(f"\nğŸ“‹ æŸ¥è¯¢ 1: ä½¿ç”¨æ„å›¾ '{intent_name}' çš„è®ºæ–‡")
        print("-" * 70)
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (p:Paper)-[:CONTAINS_EVENT]->(e:AnalysisEvent)-[:TARGETS_INTENT]->(i:Intent {name: $intent})
                RETURN DISTINCT p.title as title, p.year as year
                ORDER BY p.year DESC
            """, intent=intent_name)
            
            papers = list(result)
            print(f"æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡:\n")
            for idx, record in enumerate(papers, 1):
                print(f"{idx:2d}. [{record['year']}] {record['title'][:70]}...")
    
    def query_2_method_combinations(self):
        """æŸ¥è¯¢å¸¸è§çš„æ–¹æ³•ç»„åˆï¼ˆåŒä¸€ç¯‡è®ºæ–‡ä¸­ä½¿ç”¨çš„å¤šä¸ªæ–¹æ³•ï¼‰"""
        print(f"\nğŸ”¬ æŸ¥è¯¢ 2: å¸¸è§çš„æ–¹æ³•ç»„åˆ")
        print("-" * 70)
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (p:Paper)-[:CONTAINS_EVENT]->(e:AnalysisEvent)-[:USES_METHOD]->(m:Method)
                WITH p, collect(DISTINCT m.name) as methods
                WHERE size(methods) > 1
                RETURN methods, count(p) as paper_count
                ORDER BY paper_count DESC
                LIMIT 10
            """)
            
            for idx, record in enumerate(result, 1):
                methods = record['methods']
                count = record['paper_count']
                print(f"\n{idx}. ä½¿ç”¨æ¬¡æ•°: {count}")
                for method in methods:
                    print(f"   - {method}")
    
    def query_3_intent_method_matrix(self):
        """æŸ¥è¯¢æ„å›¾-æ–¹æ³•å…³è”çŸ©é˜µ"""
        print(f"\nğŸ¯ æŸ¥è¯¢ 3: æ„å›¾-æ–¹æ³•å…³è”çŸ©é˜µ (Top 5 æ„å›¾ Ã— Top 5 æ–¹æ³•)")
        print("-" * 70)
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (i:Intent)<-[:TARGETS_INTENT]-(e:AnalysisEvent)-[:USES_METHOD]->(m:Method)
                RETURN i.name as intent, m.name as method, count(*) as count
                ORDER BY count DESC
                LIMIT 20
            """)
            
            print(f"\n{'æ„å›¾':<40s} | {'æ–¹æ³•':<40s} | æ¬¡æ•°")
            print("-" * 100)
            for record in result:
                print(f"{record['intent']:<40s} | {record['method']:<40s} | {record['count']:3d}")
    
    def query_4_data_input_patterns(self):
        """æŸ¥è¯¢è¾“å…¥æ•°æ®çš„ä½¿ç”¨æ¨¡å¼"""
        print(f"\nğŸ“Š æŸ¥è¯¢ 4: ä¸åŒæ„å›¾ä¸‹çš„å¸¸ç”¨è¾“å…¥æ•°æ®")
        print("-" * 70)
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (i:Intent)<-[:TARGETS_INTENT]-(e:AnalysisEvent)-[:REQUIRES_INPUT]->(d:Data)
                WITH i.name as intent, d.name as data_type, count(*) as usage_count
                ORDER BY intent, usage_count DESC
                RETURN intent, collect({data: data_type, count: usage_count})[0..5] as top_data
            """)
            
            for record in result:
                intent = record['intent']
                top_data = record['top_data']
                print(f"\n{intent}:")
                for item in top_data:
                    print(f"  - {item['data']}: {item['count']} æ¬¡")
    
    def query_5_paper_analysis_depth(self):
        """æŸ¥è¯¢è®ºæ–‡çš„åˆ†ææ·±åº¦ï¼ˆåˆ†ææ­¥éª¤æ•°é‡ï¼‰"""
        print(f"\nğŸ“ˆ æŸ¥è¯¢ 5: è®ºæ–‡åˆ†ææ·±åº¦åˆ†å¸ƒ")
        print("-" * 70)
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (p:Paper)-[:CONTAINS_EVENT]->(e:AnalysisEvent)
                WITH p, count(e) as step_count
                RETURN step_count, count(p) as paper_count
                ORDER BY step_count
            """)
            
            print(f"\n{'åˆ†ææ­¥éª¤æ•°':<15s} | {'è®ºæ–‡æ•°é‡':<10s} | åˆ†å¸ƒ")
            print("-" * 60)
            for record in result:
                steps = record['step_count']
                count = record['paper_count']
                bar = "â–ˆ" * count
                print(f"{steps:<15d} | {count:<10d} | {bar}")
    
    def query_6_dataset_method_preference(self):
        """æŸ¥è¯¢ä¸åŒæ•°æ®é›†åå¥½ä½¿ç”¨çš„æ–¹æ³•"""
        print(f"\nğŸ’¾ æŸ¥è¯¢ 6: ä¸åŒæ•°æ®é›†å¸¸ç”¨çš„åˆ†ææ–¹æ³•")
        print("-" * 70)
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (d:Dataset)<-[:USES_DATASET]-(p:Paper)-[:CONTAINS_EVENT]->(e:AnalysisEvent)-[:USES_METHOD]->(m:Method)
                WITH d.name as dataset, m.name as method, count(*) as usage_count
                ORDER BY dataset, usage_count DESC
                RETURN dataset, collect({method: method, count: usage_count})[0..3] as top_methods
            """)
            
            for record in result:
                dataset = record['dataset']
                top_methods = record['top_methods']
                if top_methods:
                    print(f"\n{dataset}:")
                    for item in top_methods:
                        print(f"  - {item['method']}: {item['count']} æ¬¡")
    
    def query_7_conclusion_types(self):
        """æŸ¥è¯¢ç»“è®ºç±»å‹åˆ†å¸ƒ"""
        print(f"\nğŸ’¡ æŸ¥è¯¢ 7: ç»“è®ºå…³é”®è¯åˆ†æ")
        print("-" * 70)
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (c:Conclusion)
                RETURN c.text as conclusion
            """)
            
            # ç®€å•çš„å…³é”®è¯ç»Ÿè®¡
            keywords = {
                "è¶‹åŠ¿": 0,
                "ç©ºç™½": 0,
                "æœ‰æ•ˆ": 0,
                "éªŒè¯": 0,
                "è¯†åˆ«": 0,
                "è¯„ä¼°": 0,
                "åˆ†æ": 0,
                "é¢„æµ‹": 0
            }
            
            total = 0
            for record in result:
                conclusion = record['conclusion']
                total += 1
                for keyword in keywords:
                    if keyword in conclusion:
                        keywords[keyword] += 1
            
            print(f"\næ€»ç»“è®ºæ•°: {total}")
            print(f"\nå…³é”®è¯å‡ºç°é¢‘ç‡:")
            for keyword, count in sorted(keywords.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / total * 100) if total > 0 else 0
                bar = "â–ˆ" * int(percentage / 2)
                print(f"  {keyword:<10s}: {count:3d} æ¬¡ ({percentage:5.1f}%) {bar}")
    
    def query_8_find_similar_papers(self, paper_title: str):
        """æŸ¥æ‰¾ä¸æŒ‡å®šè®ºæ–‡ç›¸ä¼¼çš„è®ºæ–‡ï¼ˆåŸºäºæ„å›¾å’Œæ–¹æ³•ï¼‰"""
        print(f"\nğŸ” æŸ¥è¯¢ 8: æŸ¥æ‰¾ç›¸ä¼¼è®ºæ–‡")
        print("-" * 70)
        print(f"å‚è€ƒè®ºæ–‡: {paper_title[:60]}...")
        
        with self.driver.session() as session:
            result = session.run("""
                MATCH (p1:Paper {title: $title})-[:CONTAINS_EVENT]->(e1:AnalysisEvent)
                MATCH (e1)-[:TARGETS_INTENT]->(i:Intent)
                MATCH (e1)-[:USES_METHOD]->(m:Method)
                
                MATCH (p2:Paper)-[:CONTAINS_EVENT]->(e2:AnalysisEvent)
                WHERE p2 <> p1
                MATCH (e2)-[:TARGETS_INTENT]->(i)
                MATCH (e2)-[:USES_METHOD]->(m)
                
                WITH p2, count(DISTINCT i) + count(DISTINCT m) as similarity_score
                RETURN p2.title as title, p2.year as year, similarity_score
                ORDER BY similarity_score DESC
                LIMIT 5
            """, title=paper_title)
            
            print(f"\nç›¸ä¼¼è®ºæ–‡ (æŒ‰ç›¸ä¼¼åº¦æ’åº):\n")
            for idx, record in enumerate(result, 1):
                print(f"{idx}. [{record['year']}] {record['title'][:60]}...")
                print(f"   ç›¸ä¼¼åº¦å¾—åˆ†: {record['similarity_score']}")


def main():
    """è¿è¡Œç¤ºä¾‹æŸ¥è¯¢"""
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  çŸ¥è¯†å›¾è°±æŸ¥è¯¢ç¤ºä¾‹                                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    query_tool = KnowledgeGraphQuery()
    
    try:
        # è¿è¡Œå„ç§æŸ¥è¯¢
        query_tool.query_1_papers_by_intent("æŠ€æœ¯è¶‹åŠ¿åˆ†æ (Trend Analysis)")
        query_tool.query_2_method_combinations()
        query_tool.query_3_intent_method_matrix()
        query_tool.query_4_data_input_patterns()
        query_tool.query_5_paper_analysis_depth()
        query_tool.query_6_dataset_method_preference()
        query_tool.query_7_conclusion_types()
        
        # æŸ¥æ‰¾ç›¸ä¼¼è®ºæ–‡
        query_tool.query_8_find_similar_papers(
            "A Trend Analysis Method for IoT Technologies Using Patent Dataset with Goal and Approach Concepts"
        )
        
        print("\n" + "="*70)
        print("âœ“ æ‰€æœ‰æŸ¥è¯¢å®Œæˆ")
        print("="*70 + "\n")
        
    finally:
        query_tool.close()


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ æŸ¥è¯¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
