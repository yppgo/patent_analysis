#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«¯åˆ°ç«¯æµ‹è¯•ï¼šStrategist â†’ Methodologist â†’ Coding Agent V4.2

ç›®æ ‡ï¼š
1. éªŒè¯å®Œæ•´æµç¨‹å¯ä»¥æ­£å¸¸è¿è¡Œ
2. è¯„ä¼° Coding Agent V4.2 çš„ä»£ç ç”Ÿæˆè´¨é‡
3. ç¡®è®¤ç”Ÿæˆçš„ä»£ç å¯ä»¥æˆåŠŸæ‰§è¡Œ
"""

import json
import os
import sys
import time
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import pandas as pd
from src.utils.llm_client import get_llm_client
from src.graphs.causal_graph_query import CausalGraphQuery
from src.graphs.method_graph_query import MethodGraphQuery
from src.agents.strategist import StrategistAgent
from src.agents.methodologist import MethodologistAgent
from src.agents.coding_agent_v4_2 import CodingAgentV4_2


def load_test_data(data_file: str, sheet_name: str = "sheet1") -> pd.DataFrame:
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    try:
        df = pd.read_excel(data_file, sheet_name=sheet_name)
        print(f"  âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape}")
        print(f"  åˆ—å: {list(df.columns)[:10]}...")
        return df
    except Exception as e:
        print(f"  âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None


def test_full_pipeline():
    """æµ‹è¯•ä» Strategist åˆ° Coding Agent V4.2 çš„å®Œæ•´æµç¨‹"""
    print("\n" + "=" * 80)
    print("ğŸš€ ç«¯åˆ°ç«¯æµ‹è¯•ï¼šStrategist â†’ Methodologist â†’ Coding Agent V4.2")
    print("=" * 80)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path('outputs').mkdir(exist_ok=True)
    
    # åˆå§‹åŒ–ç»„ä»¶
    print("\nğŸ“¦ Step 0: åˆå§‹åŒ–ç»„ä»¶")
    print("-" * 40)
    
    llm = get_llm_client()
    coding_llm = get_llm_client(env_prefix="CODING_")
    
    # åŠ è½½å›¾è°±
    causal_graph = CausalGraphQuery("src/graphs/data/causal/causal_ontology_extracted.json")
    method_graph = MethodGraphQuery("src/graphs/data/method/method_knowledge_base.json")
    
    # åˆå§‹åŒ– Agents
    strategist = StrategistAgent(
        llm_client=llm,
        causal_graph=causal_graph,
        method_graph=method_graph
    )
    methodologist = MethodologistAgent(llm_client=llm)
    coding_agent = CodingAgentV4_2(llm_client=coding_llm, max_iterations=15)
    
    print("  âœ… Strategist Agent (V5.0)")
    print("  âœ… Methodologist Agent (V5.0)")
    print("  âœ… Coding Agent (V4.2)")
    print("  âœ… å› æœå›¾è°±ï¼ˆ30å˜é‡ï¼Œ135è·¯å¾„ï¼‰")
    print("  âœ… æ–¹æ³•å›¾è°±ï¼ˆ50ç¯‡è®ºæ–‡ï¼‰")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("\nğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®")
    data_file = "data/new_data.XLSX"
    test_data = load_test_data(data_file, "sheet1")
    
    if test_data is None:
        print("âŒ æ— æ³•åŠ è½½æµ‹è¯•æ•°æ®ï¼Œç»ˆæ­¢æµ‹è¯•")
        return
    
    # Step 1: Strategist ç”Ÿæˆè“å›¾
    print("\n" + "=" * 80)
    print("ğŸ“‹ Step 1: Strategist ç”Ÿæˆ DAG è“å›¾")
    print("=" * 80)
    
    user_input = {
        "user_goal": "åˆ†æé‡å­è®¡ç®—é¢†åŸŸçš„æŠ€æœ¯å½±å“åŠ›é©±åŠ¨å› ç´ ",
        "data_file": data_file,
        "sheet_name": "sheet1",
        "use_dag": True
    }
    
    print(f"\nğŸ“ ç”¨æˆ·è¾“å…¥:")
    print(f"  ç›®æ ‡: {user_input['user_goal']}")
    print(f"  æ•°æ®: {user_input['data_file']}")
    
    start_time = time.time()
    blueprint_result = strategist.process(user_input)
    strategist_time = time.time() - start_time
    
    # éªŒè¯è“å›¾
    assert 'blueprint' in blueprint_result, "ç¼ºå°‘ blueprint å­—æ®µ"
    blueprint = blueprint_result['blueprint']
    assert 'task_graph' in blueprint, "ç¼ºå°‘ task_graph å­—æ®µ"
    task_graph = blueprint['task_graph']
    
    print(f"\nâœ… è“å›¾ç”ŸæˆæˆåŠŸ (è€—æ—¶: {strategist_time:.1f}s)")
    print(f"  ä»»åŠ¡æ•°é‡: {len(task_graph)}")
    print(f"  ç ”ç©¶ç›®æ ‡: {blueprint.get('research_objective', 'N/A')[:60]}...")
    
    # æ‰“å°ä»»åŠ¡åˆ—è¡¨
    print(f"\nğŸ“‹ ä»»åŠ¡åˆ—è¡¨:")
    for i, task in enumerate(task_graph, 1):
        print(f"  {i}. {task['task_id']}: {task['task_type']}")
        print(f"     é—®é¢˜: {task['question'][:50]}...")
        print(f"     ä¾èµ–: {task.get('dependencies', [])}")
    
    # ä¿å­˜è“å›¾
    blueprint_file = "outputs/full_pipeline_blueprint.json"
    with open(blueprint_file, 'w', encoding='utf-8') as f:
        json.dump(blueprint_result, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ è“å›¾å·²ä¿å­˜: {blueprint_file}")
    
    # Step 2: Methodologist ç”ŸæˆæŠ€æœ¯è§„æ ¼
    print("\n" + "=" * 80)
    print("ğŸ“‹ Step 2: Methodologist ç”ŸæˆæŠ€æœ¯è§„æ ¼")
    print("=" * 80)
    
    specs = []
    methodologist_times = []
    
    for i, task in enumerate(task_graph, 1):
        print(f"\nğŸ”§ å¤„ç†ä»»åŠ¡ {i}/{len(task_graph)}: {task['task_id']}")
        
        start_time = time.time()
        spec_result = methodologist.process({'task_node': task})
        methodologist_times.append(time.time() - start_time)
        
        # éªŒè¯æŠ€æœ¯è§„æ ¼
        assert 'technical_spec' in spec_result, f"ä»»åŠ¡ {task['task_id']} ç¼ºå°‘ technical_spec"
        spec = spec_result['technical_spec']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if 'error' in spec:
            print(f"  âŒ æŠ€æœ¯è§„æ ¼ç”Ÿæˆå¤±è´¥ (è€—æ—¶: {methodologist_times[-1]:.1f}s)")
            print(f"     é”™è¯¯: {spec['error']}")
            if 'raw_response' in spec:
                print(f"     åŸå§‹å“åº”ï¼ˆå‰500å­—ç¬¦ï¼‰:")
                print(f"     {spec['raw_response'][:500]}")
            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            spec_file = f"outputs/full_pipeline_{task['task_id']}_spec_error.json"
            with open(spec_file, 'w', encoding='utf-8') as f:
                json.dump(spec_result, f, ensure_ascii=False, indent=2)
            print(f"     ğŸ’¾ é”™è¯¯å·²ä¿å­˜: {spec_file}")
            continue
        
        print(f"  âœ… æŠ€æœ¯è§„æ ¼ç”ŸæˆæˆåŠŸ (è€—æ—¶: {methodologist_times[-1]:.1f}s)")
        print(f"     å‡½æ•°å: {spec['function_name']}")
        print(f"     é€»è¾‘æ­¥éª¤: {len(spec.get('logic_flow', []))}æ­¥")
        
        specs.append(spec_result)
        
        # ä¿å­˜æŠ€æœ¯è§„æ ¼
        spec_file = f"outputs/full_pipeline_{task['task_id']}_spec.json"
        with open(spec_file, 'w', encoding='utf-8') as f:
            json.dump(spec_result, f, ensure_ascii=False, indent=2)
        print(f"     ğŸ’¾ å·²ä¿å­˜: {spec_file}")
    
    # Step 3: Coding Agent V4.2 æ‰§è¡Œä»£ç ç”Ÿæˆ
    print("\n" + "=" * 80)
    print("ğŸ“‹ Step 3: Coding Agent V4.2 ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ")
    print("=" * 80)
    
    coding_results = []
    coding_times = []
    success_count = 0
    
    for i, (task, spec_result) in enumerate(zip(task_graph, specs), 1):
        print(f"\nğŸ”§ æ‰§è¡Œä»»åŠ¡ {i}/{len(task_graph)}: {task['task_id']}")
        print(f"  å‡½æ•°å: {spec_result['technical_spec']['function_name']}")
        
        # æ¸…ç†æ—§ç»“æœæ–‡ä»¶
        task_id = task['task_id']
        expected_output_file = (
            spec_result.get('technical_spec', {}).get('output_file')
            or task.get('implementation_config', {}).get('output_file')
            or f"outputs/{task_id}_results.csv"
        )
        old_result_file = Path(expected_output_file)
        if old_result_file.exists():
            old_result_file.unlink()
            print(f"  ğŸ—‘ï¸ æ¸…ç†æ—§æ–‡ä»¶: {old_result_file}")
        
        # å‡†å¤‡è¾“å…¥
        coding_input = {
            'execution_spec': spec_result['technical_spec'],
            'current_step': task,
            'test_data': test_data,
            'previous_result': coding_results[-1] if coding_results else None
        }
        
        start_time = time.time()
        try:
            result = coding_agent.process(coding_input)
            coding_times.append(time.time() - start_time)
            
            is_valid = result.get('is_code_valid', False)
            iteration_count = result.get('iteration_count', 0)
            runtime_error = result.get('runtime_error', '')
            
            if is_valid:
                success_count += 1
                print(f"  âœ… ä»£ç ç”Ÿæˆå¹¶æ‰§è¡ŒæˆåŠŸ (è€—æ—¶: {coding_times[-1]:.1f}s, è¿­ä»£: {iteration_count}æ¬¡)")
            else:
                print(f"  âŒ ä»£ç æ‰§è¡Œå¤±è´¥ (è€—æ—¶: {coding_times[-1]:.1f}s, è¿­ä»£: {iteration_count}æ¬¡)")
                if runtime_error:
                    print(f"     é”™è¯¯: {runtime_error[:100]}...")
            
            coding_results.append(result)
            
            # ä¿å­˜ç”Ÿæˆçš„ä»£ç 
            if result.get('generated_code'):
                code_file = f"outputs/full_pipeline_{task_id}.py"
                with open(code_file, 'w', encoding='utf-8') as f:
                    f.write(result['generated_code'])
                print(f"     ğŸ’¾ ä»£ç å·²ä¿å­˜: {code_file}")
            
        except Exception as e:
            coding_times.append(time.time() - start_time)
            print(f"  âŒ æ‰§è¡Œå¼‚å¸¸: {e}")
            coding_results.append({'error': str(e), 'is_code_valid': False})
    
    # Step 4: è¯„ä¼°ç»“æœ
    print("\n" + "=" * 80)
    print("ğŸ“Š Step 4: æµ‹è¯•ç»“æœè¯„ä¼°")
    print("=" * 80)
    
    total_tasks = len(task_graph)
    success_rate = success_count / total_tasks * 100 if total_tasks > 0 else 0
    
    print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
    print(f"  Strategist è€—æ—¶: {strategist_time:.1f}s")
    print(f"  Methodologist å¹³å‡è€—æ—¶: {sum(methodologist_times)/len(methodologist_times):.1f}s")
    print(f"  Coding Agent å¹³å‡è€—æ—¶: {sum(coding_times)/len(coding_times):.1f}s")
    print(f"  æ€»è€—æ—¶: {strategist_time + sum(methodologist_times) + sum(coding_times):.1f}s")
    
    print(f"\nğŸ¯ è´¨é‡æŒ‡æ ‡:")
    print(f"  ä»»åŠ¡æ€»æ•°: {total_tasks}")
    print(f"  æˆåŠŸæ•°é‡: {success_count}")
    print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶æ£€æŸ¥:")
    for task in task_graph:
        task_id = task['task_id']
        expected_output_file = (
            task.get('implementation_config', {}).get('output_file')
            or f"outputs/{task_id}_results.csv"
        )
        result_file = Path(expected_output_file)
        code_file = Path(f"outputs/full_pipeline_{task_id}.py")
        
        if result_file.exists():
            suffix = result_file.suffix.lower()
            if suffix == '.csv':
                df = pd.read_csv(result_file)
                print(f"  âœ… {result_file}: {df.shape[0]}è¡Œ, {df.shape[1]}åˆ—")
            else:
                size = result_file.stat().st_size
                print(f"  âœ… {result_file}: å­˜åœ¨ (å¤§å°: {size} å­—èŠ‚)")
        else:
            print(f"  âŒ {result_file}: ä¸å­˜åœ¨")
        
        if code_file.exists():
            print(f"  âœ… {code_file}: å­˜åœ¨")
        else:
            print(f"  âŒ {code_file}: ä¸å­˜åœ¨")
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    if success_rate >= 80:
        print(f"\nâœ… æµ‹è¯•é€šè¿‡ï¼æˆåŠŸç‡: {success_rate:.1f}%")
        print("  å»ºè®®ï¼šå½“å‰æ–¹æ¡ˆå¯ç”¨ï¼Œç»§ç»­ä¼˜åŒ–ç»†èŠ‚")
    elif success_rate >= 50:
        print(f"\nâš ï¸ æµ‹è¯•éƒ¨åˆ†é€šè¿‡ã€‚æˆåŠŸç‡: {success_rate:.1f}%")
        print("  å»ºè®®ï¼šåˆ†æå¤±è´¥åŸå› ï¼Œä¼˜åŒ– Prompt æˆ–å¯ç”¨ execution_plan")
    else:
        print(f"\nâŒ æµ‹è¯•æœªé€šè¿‡ã€‚æˆåŠŸç‡: {success_rate:.1f}%")
        print("  å»ºè®®ï¼šæ·±å…¥åˆ†æé—®é¢˜ï¼Œè€ƒè™‘æ¶æ„è°ƒæ•´")
    
    # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
    report = {
        'test_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'user_goal': user_input['user_goal'],
        'total_tasks': total_tasks,
        'success_count': success_count,
        'success_rate': success_rate,
        'strategist_time': strategist_time,
        'methodologist_times': methodologist_times,
        'coding_times': coding_times,
        'total_time': strategist_time + sum(methodologist_times) + sum(coding_times),
        'coding_results': [
            {
                'task_id': task['task_id'],
                'is_valid': r.get('is_code_valid', False),
                'iteration_count': r.get('iteration_count', 0),
                'error': r.get('runtime_error', '') or r.get('error', '')
            }
            for task, r in zip(task_graph, coding_results)
        ]
    }
    
    report_file = "outputs/full_pipeline_test_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    return report


if __name__ == "__main__":
    test_full_pipeline()
