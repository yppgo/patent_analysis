"""æµ‹è¯•åˆ†å±‚æ¨èç³»ç»Ÿ"""
from src.graphs.causal_graph_query import CausalGraphQuery
import json

query = CausalGraphQuery()

# ç”Ÿæˆå‡è®¾
result = query.generate_hypotheses_v2({
    "domain": "é‡å­è®¡ç®—",
    "intent": "æŠ€æœ¯å½±å“åŠ›é©±åŠ¨å› ç´ åˆ†æ"
})

print("="*80)
print("åˆ†å±‚æ¨èç³»ç»Ÿæµ‹è¯•")
print("="*80)

# Step 5: å‡è®¾ç”Ÿæˆç»Ÿè®¡
hypotheses = result['step5_hypotheses']
print(f"\nğŸ“Š Step 5: å‡è®¾ç”Ÿæˆ")
print(f"  æ€»å‡è®¾æ•°: {len(hypotheses)}")

type_count = {}
for h in hypotheses:
    h_type = h['type']
    type_count[h_type] = type_count.get(h_type, 0) + 1

print(f"  ç­–ç•¥åˆ†å¸ƒ:")
for h_type, count in type_count.items():
    print(f"    - {h_type}: {count}ä¸ª")

# Step 6: åˆ†å±‚æ¨è
recommendation = result['step6_recommendation']

print(f"\n" + "="*80)
print("ğŸ¯ Step 6: åˆ†å±‚æ¨èç»“æœ")
print("="*80)

print(f"\næ€»ç»“: {recommendation['summary']}")
print(f"  - æ ¸å¿ƒæ¨è: {recommendation['core_count']}ä¸ª")
print(f"  - å¤‡é€‰æ¨è: {recommendation['alternative_count']}ä¸ª")
print(f"  - æ€»å‡è®¾æ•°: {recommendation['total_count']}ä¸ª")

# æ ¸å¿ƒæ¨èï¼ˆ3ä¸ªï¼‰
print(f"\n" + "="*80)
print("â­ æ ¸å¿ƒæ¨èï¼ˆå¿…é€‰ï¼Œ3ä¸ªï¼‰")
print("="*80)

for rec in recommendation['core_recommendations']:
    h = rec['hypothesis']
    eval_data = h['evaluation']
    
    print(f"\n{rec['rank']}. {h['id']}: {h['statement']}")
    print(f"   æ¨èç†ç”±: {rec['reason']}")
    print(f"   æ¨èç±»å‹: {rec['recommendation_type']}")
    print(f"   è¯„åˆ†:")
    print(f"     - ç»¼åˆåˆ†: {eval_data['balanced_score']:.3f}")
    print(f"     - æ–°é¢–æ€§: {eval_data['novelty_score']}")
    print(f"     - è´¨é‡: {eval_data['quality_score']:.1f}")
    print(f"   ç­–ç•¥: {h['type']}")
    print(f"   è·¯å¾„: {h['theoretical_basis']}")

# å¤‡é€‰æ¨è
if recommendation['alternative_recommendations']:
    print(f"\n" + "="*80)
    print("ğŸ’¡ å¤‡é€‰æ¨èï¼ˆå¯é€‰ï¼‰")
    print("="*80)
    
    for i, rec in enumerate(recommendation['alternative_recommendations'], 1):
        h = rec['hypothesis']
        eval_data = h['evaluation']
        
        print(f"\n{i}. {h['id']}: {h['statement']}")
        print(f"   æ¨èç†ç”±: {rec['reason']}")
        print(f"   è¯„åˆ†: ç»¼åˆ{eval_data['balanced_score']:.3f} | æ–°é¢–æ€§{eval_data['novelty_score']} | è´¨é‡{eval_data['quality_score']:.1f}")

# ä½¿ç”¨å»ºè®®
print(f"\n" + "="*80)
print("ğŸ“ ä½¿ç”¨å»ºè®®")
print("="*80)

print("""
1. æ¯•ä¸šè®ºæ–‡/é¡¹ç›®éªŒæ”¶
   â†’ é€‰æ‹©æ ¸å¿ƒæ¨èçš„å‰2ä¸ªï¼ˆç»¼åˆåˆ†æœ€é«˜ + è´¨é‡æœ€é«˜ï¼‰
   â†’ ç¡®ä¿èƒ½å®Œæˆï¼Œé™ä½é£é™©

2. å­¦æœ¯è®ºæ–‡å‘è¡¨
   â†’ é€‰æ‹©æ ¸å¿ƒæ¨èçš„å…¨éƒ¨3ä¸ª
   â†’ æ—¢æœ‰åˆ›æ–°åˆæœ‰ä¿éšœ

3. æ¢ç´¢æ€§ç ”ç©¶
   â†’ æ ¸å¿ƒæ¨è3ä¸ª + å¤‡é€‰1-2ä¸ª
   â†’ è¿½æ±‚çªç ´æ€§å‘ç°
""")

# ä¿å­˜ç»“æœ
output_file = "outputs/layered_recommendation_result.json"
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(result, f, ensure_ascii=False, indent=2)

print(f"\nğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
print("\nâœ… åˆ†å±‚æ¨èç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
