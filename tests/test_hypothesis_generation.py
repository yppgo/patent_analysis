"""
æµ‹è¯•å‡è®¾ç”Ÿæˆå™¨ï¼ˆ6ç§ç­–ç•¥ï¼‰
"""

import json
from src.graphs.causal_graph_query import CausalGraphQuery


def test_hypothesis_generation():
    """æµ‹è¯•å®Œæ•´çš„å‡è®¾ç”Ÿæˆæµç¨‹"""
    print("="*60)
    print("æµ‹è¯•: å‡è®¾ç”Ÿæˆå™¨ V2ï¼ˆ6ç§ç­–ç•¥ï¼‰")
    print("="*60)
    
    # åˆå§‹åŒ–æŸ¥è¯¢å™¨
    query = CausalGraphQuery()
    
    # æµ‹è¯•åœºæ™¯1: é‡å­è®¡ç®—é¢†åŸŸçš„æŠ€æœ¯å½±å“åŠ›åˆ†æ
    print("\nğŸ“‹ åœºæ™¯1: é‡å­è®¡ç®—é¢†åŸŸçš„æŠ€æœ¯å½±å“åŠ›åˆ†æ")
    print("-"*60)
    
    result = query.generate_hypotheses_v2({
        "domain": "é‡å­è®¡ç®—",
        "intent": "æŠ€æœ¯å½±å“åŠ›é©±åŠ¨å› ç´ åˆ†æ"
    })
    
    # æ‰“å°ç»“æœ
    print("\nâœ“ Step 1: ç”¨æˆ·è¾“å…¥")
    print(f"  é¢†åŸŸ: {result['step1_input']['domain']}")
    print(f"  æ„å›¾: {result['step1_input']['intent']}")
    
    print("\nâœ“ Step 2: æ„å›¾åˆ†æ")
    print(f"  æ£€æµ‹åˆ°çš„æ„å›¾: {result['step2_analysis']['detected_intent']}")
    print(f"  æå–çš„å…³é”®è¯: {result['step2_analysis']['extracted_keywords']}")
    print(f"  åŒ¹é…çš„ç›®æ ‡å˜é‡: {result['step2_analysis']['matched_outcome_variable']}")
    
    print("\nâœ“ Step 3: å˜é‡åŒ¹é…")
    outcome_var = result['step3_matching']['outcome_variable']
    if outcome_var:
        print(f"  ç›®æ ‡å˜é‡: {outcome_var['label']} ({outcome_var['id']})")
    print(f"  å€™é€‰é¢„æµ‹å˜é‡æ•°: {len(result['step3_matching']['candidate_predictors'])}")
    print(f"  å€™é€‰è°ƒèŠ‚å˜é‡æ•°: {len(result['step3_matching']['candidate_moderators'])}")
    print(f"  å€™é€‰ä¸­ä»‹å˜é‡æ•°: {len(result['step3_matching']['candidate_mediators'])}")
    
    print("\nâœ“ Step 4: æ–‡çŒ®æ£€æŸ¥")
    print(f"  å·²éªŒè¯è·¯å¾„æ•°: {len(result['step4_literature']['validated_paths'])}")
    print(f"  æœªæ¢ç´¢è·¯å¾„æ•°: {len(result['step4_literature']['unexplored_paths'])}")
    
    print("\nâœ“ Step 5: å‡è®¾ç”Ÿæˆï¼ˆ6ç§ç­–ç•¥ï¼‰")
    hypotheses = result['step5_hypotheses']
    print(f"  ç”Ÿæˆå‡è®¾æ€»æ•°: {len(hypotheses)}")
    
    # æŒ‰ç­–ç•¥åˆ†ç»„ç»Ÿè®¡
    strategy_count = {}
    for h in hypotheses:
        strategy = h['type']
        strategy_count[strategy] = strategy_count.get(strategy, 0) + 1
    
    print("\n  å„ç­–ç•¥ç”Ÿæˆæ•°é‡:")
    strategy_names = {
        "theory_transfer": "ç†è®ºè¿ç§»",
        "path_exploration": "è·¯å¾„æ¢ç´¢",
        "moderation": "è¾¹ç•Œæ¡ä»¶",
        "mediation": "ä¸­ä»‹æœºåˆ¶",
        "counterfactual": "åäº‹å®æ¨ç†",
        "interaction": "äº¤äº’æ•ˆåº”"
    }
    for strategy, count in strategy_count.items():
        print(f"    - {strategy_names.get(strategy, strategy)}: {count}ä¸ª")
    
    print("\n  ç”Ÿæˆçš„å‡è®¾åˆ—è¡¨:")
    for i, h in enumerate(hypotheses, 1):
        print(f"\n  å‡è®¾ {i}: {h['id']}")
        print(f"    é™ˆè¿°: {h['statement']}")
        print(f"    ç­–ç•¥: {h['strategy_description']}")
        print(f"    æ–°é¢–æ€§: {h['novelty_score']}")
        print(f"    å˜é‡: {h['variables']['independent']} â†’ {h['variables']['dependent']}")
        if h['variables']['mediator']:
            print(f"    ä¸­ä»‹å˜é‡: {h['variables']['mediator']}")
        if h['variables']['moderator']:
            print(f"    è°ƒèŠ‚å˜é‡: {h['variables']['moderator']}")
    
    print("\nâœ“ Step 6: æ’åºæ¨è")
    recommendation = result['step6_recommendation']
    print(f"  æ¨èæ€»ç»“: {recommendation['summary']}")
    print(f"  æ ¸å¿ƒæ¨èæ•°: {recommendation['core_count']}")
    print(f"  å¤‡é€‰æ¨èæ•°: {recommendation['alternative_count']}")
    
    if recommendation['core_recommendations']:
        top_rec = recommendation['core_recommendations'][0]
        top_hyp = top_rec['hypothesis']
        print(f"  æœ€æ¨èå‡è®¾: {top_hyp['id']}")
        print(f"  æ¨èç†ç”±: {top_rec['reason']}")
        print(f"  å‡è®¾é™ˆè¿°: {top_hyp['statement']}")
    
    # ä¿å­˜ç»“æœ
    output_file = "outputs/hypothesis_generation_test_result.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    return result


def test_all_strategies():
    """æµ‹è¯•æ‰€æœ‰6ç§ç­–ç•¥éƒ½èƒ½ç”Ÿæˆå‡è®¾"""
    print("\n" + "="*60)
    print("æµ‹è¯•: éªŒè¯æ‰€æœ‰6ç§ç­–ç•¥")
    print("="*60)
    
    query = CausalGraphQuery()
    
    result = query.generate_hypotheses_v2({
        "domain": "äººå·¥æ™ºèƒ½",
        "intent": "æŠ€æœ¯å½±å“åŠ›é©±åŠ¨å› ç´ åˆ†æ"
    })
    
    hypotheses = result['step5_hypotheses']
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰€æœ‰ç­–ç•¥
    strategies_found = set(h['type'] for h in hypotheses)
    expected_strategies = {
        "theory_transfer",
        "path_exploration",
        "moderation",
        "mediation",
        "counterfactual",
        "interaction"
    }
    
    print(f"\nâœ“ ç”Ÿæˆçš„ç­–ç•¥ç±»å‹: {strategies_found}")
    print(f"âœ“ é¢„æœŸçš„ç­–ç•¥ç±»å‹: {expected_strategies}")
    
    missing = expected_strategies - strategies_found
    if missing:
        print(f"\nâš ï¸  ç¼ºå¤±çš„ç­–ç•¥: {missing}")
    else:
        print(f"\nâœ… æ‰€æœ‰6ç§ç­–ç•¥éƒ½å·²ç”Ÿæˆå‡è®¾ï¼")
    
    # æ£€æŸ¥æ–°é¢–æ€§è¯„åˆ†
    print(f"\nâœ“ æ–°é¢–æ€§è¯„åˆ†èŒƒå›´:")
    scores = [h['novelty_score'] for h in hypotheses]
    print(f"  æœ€é«˜: {max(scores)}")
    print(f"  æœ€ä½: {min(scores)}")
    print(f"  å¹³å‡: {sum(scores)/len(scores):.2f}")
    
    assert len(hypotheses) >= 5, "åº”è¯¥è‡³å°‘ç”Ÿæˆ5ä¸ªå‡è®¾"
    assert all(0.6 <= h['novelty_score'] <= 1.0 for h in hypotheses), "æ–°é¢–æ€§è¯„åˆ†åº”åœ¨0.6-1.0ä¹‹é—´"
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")


def test_variable_matching():
    """æµ‹è¯•å˜é‡åŒ¹é…çš„å‡†ç¡®æ€§"""
    print("\n" + "="*60)
    print("æµ‹è¯•: å˜é‡åŒ¹é…å‡†ç¡®æ€§")
    print("="*60)
    
    query = CausalGraphQuery()
    
    # æµ‹è¯•ä¸åŒçš„æ„å›¾
    test_cases = [
        {
            "intent": "æŠ€æœ¯å½±å“åŠ›åˆ†æ",
            "expected_outcome": "V16_tech_impact"
        },
        {
            "intent": "æŠ€æœ¯çªç ´æ€§ç ”ç©¶",
            "expected_outcome": "V17_tech_breakthrough"
        },
        {
            "intent": "å•†ä¸šä»·å€¼è¯„ä¼°",
            "expected_outcome": "V19_commercial_value"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i}: {case['intent']}")
        
        result = query.generate_hypotheses_v2({
            "domain": "æµ‹è¯•é¢†åŸŸ",
            "intent": case['intent']
        })
        
        matched_var = result['step2_analysis']['matched_outcome_variable']
        print(f"  åŒ¹é…çš„å˜é‡: {matched_var}")
        print(f"  é¢„æœŸçš„å˜é‡: {case['expected_outcome']}")
        
        if matched_var == case['expected_outcome']:
            print(f"  âœ… åŒ¹é…æ­£ç¡®")
        else:
            print(f"  âš ï¸  åŒ¹é…ä¸ç¬¦åˆé¢„æœŸ")
    
    print("\nâœ… å˜é‡åŒ¹é…æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    print("\n" + "ğŸš€ å¼€å§‹æµ‹è¯•å‡è®¾ç”Ÿæˆå™¨" + "\n")
    
    # æµ‹è¯•1: å®Œæ•´æµç¨‹
    result = test_hypothesis_generation()
    
    # æµ‹è¯•2: æ‰€æœ‰ç­–ç•¥
    test_all_strategies()
    
    # æµ‹è¯•3: å˜é‡åŒ¹é…
    test_variable_matching()
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("="*60)
